{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-be0b91895dfb>:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Yahoo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ethdf = yf.download('ETH-USD', start='2019-01-01', end='2023-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00+00:00</th>\n",
       "      <td>133.418152</td>\n",
       "      <td>141.397507</td>\n",
       "      <td>132.650711</td>\n",
       "      <td>140.819412</td>\n",
       "      <td>140.819412</td>\n",
       "      <td>2258709868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02 00:00:00+00:00</th>\n",
       "      <td>141.519516</td>\n",
       "      <td>156.929138</td>\n",
       "      <td>140.650955</td>\n",
       "      <td>155.047684</td>\n",
       "      <td>155.047684</td>\n",
       "      <td>3328240369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03 00:00:00+00:00</th>\n",
       "      <td>155.196045</td>\n",
       "      <td>155.863052</td>\n",
       "      <td>147.198364</td>\n",
       "      <td>149.135010</td>\n",
       "      <td>149.135010</td>\n",
       "      <td>2676164880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04 00:00:00+00:00</th>\n",
       "      <td>148.912888</td>\n",
       "      <td>156.878983</td>\n",
       "      <td>147.907104</td>\n",
       "      <td>154.581940</td>\n",
       "      <td>154.581940</td>\n",
       "      <td>3126192535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05 00:00:00+00:00</th>\n",
       "      <td>154.337418</td>\n",
       "      <td>160.824890</td>\n",
       "      <td>154.337418</td>\n",
       "      <td>155.638596</td>\n",
       "      <td>155.638596</td>\n",
       "      <td>3338211928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27 00:00:00+00:00</th>\n",
       "      <td>1226.987061</td>\n",
       "      <td>1230.418091</td>\n",
       "      <td>1205.895630</td>\n",
       "      <td>1212.791626</td>\n",
       "      <td>1212.791626</td>\n",
       "      <td>4091530737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 00:00:00+00:00</th>\n",
       "      <td>1212.736572</td>\n",
       "      <td>1213.128906</td>\n",
       "      <td>1185.702148</td>\n",
       "      <td>1189.986084</td>\n",
       "      <td>1189.986084</td>\n",
       "      <td>4991669631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29 00:00:00+00:00</th>\n",
       "      <td>1190.010132</td>\n",
       "      <td>1204.141602</td>\n",
       "      <td>1188.360229</td>\n",
       "      <td>1201.595337</td>\n",
       "      <td>1201.595337</td>\n",
       "      <td>4132233940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 00:00:00+00:00</th>\n",
       "      <td>1201.569580</td>\n",
       "      <td>1202.034668</td>\n",
       "      <td>1187.462524</td>\n",
       "      <td>1199.232788</td>\n",
       "      <td>1199.232788</td>\n",
       "      <td>4055668253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 00:00:00+00:00</th>\n",
       "      <td>1199.360107</td>\n",
       "      <td>1205.088623</td>\n",
       "      <td>1194.203735</td>\n",
       "      <td>1196.771240</td>\n",
       "      <td>1196.771240</td>\n",
       "      <td>3018513333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "2019-01-01 00:00:00+00:00  133.418152   141.397507   132.650711   140.819412    \n",
       "2019-01-02 00:00:00+00:00  141.519516   156.929138   140.650955   155.047684    \n",
       "2019-01-03 00:00:00+00:00  155.196045   155.863052   147.198364   149.135010    \n",
       "2019-01-04 00:00:00+00:00  148.912888   156.878983   147.907104   154.581940    \n",
       "2019-01-05 00:00:00+00:00  154.337418   160.824890   154.337418   155.638596    \n",
       "...                               ...          ...          ...          ...    \n",
       "2022-12-27 00:00:00+00:00  1226.987061  1230.418091  1205.895630  1212.791626   \n",
       "2022-12-28 00:00:00+00:00  1212.736572  1213.128906  1185.702148  1189.986084   \n",
       "2022-12-29 00:00:00+00:00  1190.010132  1204.141602  1188.360229  1201.595337   \n",
       "2022-12-30 00:00:00+00:00  1201.569580  1202.034668  1187.462524  1199.232788   \n",
       "2022-12-31 00:00:00+00:00  1199.360107  1205.088623  1194.203735  1196.771240   \n",
       "\n",
       "                             Adj Close      Volume  \n",
       "Date                                                \n",
       "2019-01-01 00:00:00+00:00  140.819412   2258709868  \n",
       "2019-01-02 00:00:00+00:00  155.047684   3328240369  \n",
       "2019-01-03 00:00:00+00:00  149.135010   2676164880  \n",
       "2019-01-04 00:00:00+00:00  154.581940   3126192535  \n",
       "2019-01-05 00:00:00+00:00  155.638596   3338211928  \n",
       "...                               ...          ...  \n",
       "2022-12-27 00:00:00+00:00  1212.791626  4091530737  \n",
       "2022-12-28 00:00:00+00:00  1189.986084  4991669631  \n",
       "2022-12-29 00:00:00+00:00  1201.595337  4132233940  \n",
       "2022-12-30 00:00:00+00:00  1199.232788  4055668253  \n",
       "2022-12-31 00:00:00+00:00  1196.771240  3018513333  \n",
       "\n",
       "[1461 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Explore tweets with VADER sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('ETH_sent.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969417 entries, 0 to 1969416\n",
      "Data columns (total 27 columns):\n",
      " #   Column                           Dtype         \n",
      "---  ------                           -----         \n",
      " 0   created_at                       object        \n",
      " 1   edit_history_tweet_ids           object        \n",
      " 2   author_id                        object        \n",
      " 3   lang                             object        \n",
      " 4   conversation_id                  object        \n",
      " 5   text                             object        \n",
      " 6   id                               object        \n",
      " 7   reply_settings                   object        \n",
      " 8   public_metrics.retweet_count     int64         \n",
      " 9   public_metrics.reply_count       int64         \n",
      " 10  public_metrics.like_count        int64         \n",
      " 11  public_metrics.quote_count       int64         \n",
      " 12  public_metrics.impression_count  int64         \n",
      " 13  referenced_tweets                object        \n",
      " 14  in_reply_to_user_id              object        \n",
      " 15  geo.place_id                     object        \n",
      " 16  geo.coordinates.type             object        \n",
      " 17  geo.coordinates.coordinates      object        \n",
      " 18  withheld.copyright               object        \n",
      " 19  withheld.country_codes           object        \n",
      " 20  withheld.scope                   object        \n",
      " 21  time                             datetime64[ns]\n",
      " 22  clean_tweets                     object        \n",
      " 23  neg                              float64       \n",
      " 24  neu                              float64       \n",
      " 25  pos                              float64       \n",
      " 26  compound                         float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(5), object(17)\n",
      "memory usage: 405.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'edit_history_tweet_ids', 'author_id', 'lang',\n",
       "       'conversation_id', 'text', 'id', 'reply_settings',\n",
       "       'public_metrics.retweet_count', 'public_metrics.reply_count',\n",
       "       'public_metrics.like_count', 'public_metrics.quote_count',\n",
       "       'public_metrics.impression_count', 'referenced_tweets',\n",
       "       'in_reply_to_user_id', 'geo.place_id', 'geo.coordinates.type',\n",
       "       'geo.coordinates.coordinates', 'withheld.copyright',\n",
       "       'withheld.country_codes', 'withheld.scope', 'time', 'clean_tweets',\n",
       "       'neg', 'neu', 'pos', 'compound'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethereum sentiment mean for the period: 0.1825044641129837\n"
     ]
    }
   ],
   "source": [
    "print(f'Ethereum sentiment mean for the period: {df.compound.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = ['compound', 'clean_tweets', 'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-fa723974454a>:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  means = df.groupby(pd.Grouper(freq='1D')).mean()\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average sentiment for each day\n",
    "\n",
    "means = df.groupby(pd.Grouper(freq='1D')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "fig, ax = plt.subplots(figsize=(8, 10), nrows=2)\n",
    "\n",
    "means.compound.plot(ax=ax[0], color='#D25380', linewidth=0.8)\n",
    "\n",
    "ax[0].spines[[ 'top', 'right', 'bottom']].set_visible(False)\n",
    "\n",
    "ax[0].set_title('Sentiment Scores (ETH)')\n",
    "\n",
    "ax[0].axes.get_xaxis().set_visible(False)\n",
    "\n",
    "\n",
    "# Prices\n",
    "\n",
    "ethdf[['Adj Close']].plot(color='#434871', ax=ax[1])\n",
    "\n",
    "ax[1].legend().set_visible(False)\n",
    "\n",
    "ax[1].spines[[ 'top', 'right']].set_visible(False)\n",
    "\n",
    "ax[1].set_title('Ethereum Closing Prices (USD)');\n",
    "\n",
    "#plt.savefig('Ethereum.png', dpi=300, facecolor='white',bbox_inches='tight' );"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Dickey Fuller test - stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistics: -3.6169324206775344\n",
      "p-value: 0.005445446202998058\n",
      "critical_values: {'1%': -3.4348929812602784, '5%': -2.863546418485167, '10%': -2.5678382024888378}\n",
      "Series is stationary\n"
     ]
    }
   ],
   "source": [
    "result = adfuller(means['compound'])\n",
    "print(f'Test Statistics: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "print(f'critical_values: {result[4]}')\n",
    "if result[1] > 0.05:\n",
    "    print(\"Series is not stationary\")\n",
    "else:\n",
    "    print(\"Series is stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistics: -1.3896350950139478\n",
      "p-value: 0.5872349735947685\n",
      "critical_values: {'1%': -3.434889827343955, '5%': -2.863545026607168, '10%': -2.5678374612882515}\n",
      "Series is not stationary\n"
     ]
    }
   ],
   "source": [
    "result1 = adfuller(ethdf['Adj Close'])\n",
    "print(f'Test Statistics: {result1[0]}')\n",
    "print(f'p-value: {result1[1]}')\n",
    "print(f'critical_values: {result1[4]}')\n",
    "if result1[1] > 0.05:\n",
    "    print(\"Series is not stationary\")\n",
    "else:\n",
    "    print(\"Series is stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethdf[['transformed']] = ethdf[['Adj Close']].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the log returns\n",
    "\n",
    "ethdf['logret'] = np.log1p(ethdf[['Adj Close']].pct_change())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistics: -9.601879988840484\n",
      "p-value: 1.9109311638496249e-16\n",
      "critical_values: {'1%': -3.434889827343955, '5%': -2.863545026607168, '10%': -2.5678374612882515}\n",
      "Series is stationary\n"
     ]
    }
   ],
   "source": [
    "result2 = adfuller(ethdf['transformed'].dropna())\n",
    "print(f'Test Statistics: {result2[0]}')\n",
    "print(f'p-value: {result2[1]}')\n",
    "print(f'critical_values: {result2[4]}')\n",
    "if result2[1] > 0.05:\n",
    "    print(\"Series is not stationary\")\n",
    "else:\n",
    "    print(\"Series is stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistics: -11.42404054702981\n",
      "p-value: 6.763610406213626e-21\n",
      "critical_values: {'1%': -3.4348678719530934, '5%': -2.863535337271721, '10%': -2.5678323015457787}\n",
      "Series is stationary\n"
     ]
    }
   ],
   "source": [
    "result3 = adfuller(ethdf['logret'].dropna())\n",
    "print(f'Test Statistics: {result3[0]}')\n",
    "print(f'p-value: {result3[1]}')\n",
    "print(f'critical_values: {result3[4]}')\n",
    "if result3[1] > 0.05:\n",
    "    print(\"Series is not stationary\")\n",
    "else:\n",
    "    print(\"Series is stationary\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethdf = ethdf.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedf = pd.merge_ordered(ethdf, means, left_on=ethdf.index, right_on=means.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>transformed</th>\n",
       "      <th>logret</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>public_metrics.reply_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "      <th>public_metrics.impression_count</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>133.418152</td>\n",
       "      <td>141.397507</td>\n",
       "      <td>132.650711</td>\n",
       "      <td>140.819412</td>\n",
       "      <td>140.819412</td>\n",
       "      <td>2258709868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.536208</td>\n",
       "      <td>0.161920</td>\n",
       "      <td>1.847030</td>\n",
       "      <td>0.084622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023793</td>\n",
       "      <td>0.842407</td>\n",
       "      <td>0.133793</td>\n",
       "      <td>0.312475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>141.519516</td>\n",
       "      <td>156.929138</td>\n",
       "      <td>140.650955</td>\n",
       "      <td>155.047684</td>\n",
       "      <td>155.047684</td>\n",
       "      <td>3328240369</td>\n",
       "      <td>14.228271</td>\n",
       "      <td>0.096254</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.497183</td>\n",
       "      <td>3.096479</td>\n",
       "      <td>0.129577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024786</td>\n",
       "      <td>0.869537</td>\n",
       "      <td>0.105675</td>\n",
       "      <td>0.209722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>155.196045</td>\n",
       "      <td>155.863052</td>\n",
       "      <td>147.198364</td>\n",
       "      <td>149.135010</td>\n",
       "      <td>149.135010</td>\n",
       "      <td>2676164880</td>\n",
       "      <td>-5.912674</td>\n",
       "      <td>-0.038881</td>\n",
       "      <td>1.133380</td>\n",
       "      <td>1.786313</td>\n",
       "      <td>3.666899</td>\n",
       "      <td>0.175279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049217</td>\n",
       "      <td>0.843096</td>\n",
       "      <td>0.107677</td>\n",
       "      <td>0.193104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>148.912888</td>\n",
       "      <td>156.878983</td>\n",
       "      <td>147.907104</td>\n",
       "      <td>154.581940</td>\n",
       "      <td>154.581940</td>\n",
       "      <td>3126192535</td>\n",
       "      <td>5.446930</td>\n",
       "      <td>0.035872</td>\n",
       "      <td>1.023338</td>\n",
       "      <td>0.328147</td>\n",
       "      <td>2.881895</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>0.871862</td>\n",
       "      <td>0.090369</td>\n",
       "      <td>0.156892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>154.337418</td>\n",
       "      <td>160.824890</td>\n",
       "      <td>154.337418</td>\n",
       "      <td>155.638596</td>\n",
       "      <td>155.638596</td>\n",
       "      <td>3338211928</td>\n",
       "      <td>1.056656</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.243357</td>\n",
       "      <td>2.046853</td>\n",
       "      <td>0.119580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038029</td>\n",
       "      <td>0.853272</td>\n",
       "      <td>0.108684</td>\n",
       "      <td>0.212567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>1226.987061</td>\n",
       "      <td>1230.418091</td>\n",
       "      <td>1205.895630</td>\n",
       "      <td>1212.791626</td>\n",
       "      <td>1212.791626</td>\n",
       "      <td>4091530737</td>\n",
       "      <td>-14.182739</td>\n",
       "      <td>-0.011626</td>\n",
       "      <td>0.408191</td>\n",
       "      <td>0.308532</td>\n",
       "      <td>2.368601</td>\n",
       "      <td>0.081229</td>\n",
       "      <td>233.391809</td>\n",
       "      <td>0.026633</td>\n",
       "      <td>0.920326</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.093291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>1212.736572</td>\n",
       "      <td>1213.128906</td>\n",
       "      <td>1185.702148</td>\n",
       "      <td>1189.986084</td>\n",
       "      <td>1189.986084</td>\n",
       "      <td>4991669631</td>\n",
       "      <td>-22.805542</td>\n",
       "      <td>-0.018983</td>\n",
       "      <td>0.303956</td>\n",
       "      <td>0.199861</td>\n",
       "      <td>1.904927</td>\n",
       "      <td>0.124219</td>\n",
       "      <td>155.055517</td>\n",
       "      <td>0.013990</td>\n",
       "      <td>0.937352</td>\n",
       "      <td>0.048659</td>\n",
       "      <td>0.103310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>1190.010132</td>\n",
       "      <td>1204.141602</td>\n",
       "      <td>1188.360229</td>\n",
       "      <td>1201.595337</td>\n",
       "      <td>1201.595337</td>\n",
       "      <td>4132233940</td>\n",
       "      <td>11.609253</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.129555</td>\n",
       "      <td>1.192982</td>\n",
       "      <td>1.029015</td>\n",
       "      <td>0.031714</td>\n",
       "      <td>116.923752</td>\n",
       "      <td>0.034654</td>\n",
       "      <td>0.881471</td>\n",
       "      <td>0.083882</td>\n",
       "      <td>0.147959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>1201.569580</td>\n",
       "      <td>1202.034668</td>\n",
       "      <td>1187.462524</td>\n",
       "      <td>1199.232788</td>\n",
       "      <td>1199.232788</td>\n",
       "      <td>4055668253</td>\n",
       "      <td>-2.362549</td>\n",
       "      <td>-0.001968</td>\n",
       "      <td>0.139172</td>\n",
       "      <td>0.671419</td>\n",
       "      <td>0.803123</td>\n",
       "      <td>0.029192</td>\n",
       "      <td>57.758995</td>\n",
       "      <td>0.034481</td>\n",
       "      <td>0.876810</td>\n",
       "      <td>0.088715</td>\n",
       "      <td>0.179949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>1199.360107</td>\n",
       "      <td>1205.088623</td>\n",
       "      <td>1194.203735</td>\n",
       "      <td>1196.771240</td>\n",
       "      <td>1196.771240</td>\n",
       "      <td>3018513333</td>\n",
       "      <td>-2.461548</td>\n",
       "      <td>-0.002055</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.026263</td>\n",
       "      <td>143.939394</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>0.912444</td>\n",
       "      <td>0.071141</td>\n",
       "      <td>0.139988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          key_0         Open         High          Low        Close  \\\n",
       "0    2019-01-01  133.418152   141.397507   132.650711   140.819412    \n",
       "1    2019-01-02  141.519516   156.929138   140.650955   155.047684    \n",
       "2    2019-01-03  155.196045   155.863052   147.198364   149.135010    \n",
       "3    2019-01-04  148.912888   156.878983   147.907104   154.581940    \n",
       "4    2019-01-05  154.337418   160.824890   154.337418   155.638596    \n",
       "...         ...         ...          ...          ...          ...    \n",
       "1456 2022-12-27  1226.987061  1230.418091  1205.895630  1212.791626   \n",
       "1457 2022-12-28  1212.736572  1213.128906  1185.702148  1189.986084   \n",
       "1458 2022-12-29  1190.010132  1204.141602  1188.360229  1201.595337   \n",
       "1459 2022-12-30  1201.569580  1202.034668  1187.462524  1199.232788   \n",
       "1460 2022-12-31  1199.360107  1205.088623  1194.203735  1196.771240   \n",
       "\n",
       "        Adj Close      Volume  transformed    logret  \\\n",
       "0     140.819412   2258709868 NaN          NaN         \n",
       "1     155.047684   3328240369  14.228271    0.096254   \n",
       "2     149.135010   2676164880 -5.912674    -0.038881   \n",
       "3     154.581940   3126192535  5.446930     0.035872   \n",
       "4     155.638596   3338211928  1.056656     0.006812   \n",
       "...          ...          ...       ...          ...   \n",
       "1456  1212.791626  4091530737 -14.182739   -0.011626   \n",
       "1457  1189.986084  4991669631 -22.805542   -0.018983   \n",
       "1458  1201.595337  4132233940  11.609253    0.009709   \n",
       "1459  1199.232788  4055668253 -2.362549    -0.001968   \n",
       "1460  1196.771240  3018513333 -2.461548    -0.002055   \n",
       "\n",
       "      public_metrics.retweet_count  public_metrics.reply_count  \\\n",
       "0     0.536208                      0.161920                     \n",
       "1     0.797183                      0.497183                     \n",
       "2     1.133380                      1.786313                     \n",
       "3     1.023338                      0.328147                     \n",
       "4     0.630769                      0.243357                     \n",
       "...        ...                           ...                     \n",
       "1456  0.408191                      0.308532                     \n",
       "1457  0.303956                      0.199861                     \n",
       "1458  0.129555                      1.192982                     \n",
       "1459  0.139172                      0.671419                     \n",
       "1460  0.155556                      0.161616                     \n",
       "\n",
       "      public_metrics.like_count  public_metrics.quote_count  \\\n",
       "0     1.847030                   0.084622                     \n",
       "1     3.096479                   0.129577                     \n",
       "2     3.666899                   0.175279                     \n",
       "3     2.881895                   0.099010                     \n",
       "4     2.046853                   0.119580                     \n",
       "...        ...                        ...                     \n",
       "1456  2.368601                   0.081229                     \n",
       "1457  1.904927                   0.124219                     \n",
       "1458  1.029015                   0.031714                     \n",
       "1459  0.803123                   0.029192                     \n",
       "1460  0.963636                   0.026263                     \n",
       "\n",
       "      public_metrics.impression_count       neg       neu       pos  compound  \n",
       "0     0.000000                         0.023793  0.842407  0.133793  0.312475  \n",
       "1     0.000000                         0.024786  0.869537  0.105675  0.209722  \n",
       "2     0.000000                         0.049217  0.843096  0.107677  0.193104  \n",
       "3     0.000000                         0.037755  0.871862  0.090369  0.156892  \n",
       "4     0.000000                         0.038029  0.853272  0.108684  0.212567  \n",
       "...        ...                              ...       ...       ...       ...  \n",
       "1456  233.391809                       0.026633  0.920326  0.053045  0.093291  \n",
       "1457  155.055517                       0.013990  0.937352  0.048659  0.103310  \n",
       "1458  116.923752                       0.034654  0.881471  0.083882  0.147959  \n",
       "1459  57.758995                        0.034481  0.876810  0.088715  0.179949  \n",
       "1460  143.939394                       0.016412  0.912444  0.071141  0.139988  \n",
       "\n",
       "[1461 rows x 18 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformed</th>\n",
       "      <th>compound</th>\n",
       "      <th>logret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.228271</td>\n",
       "      <td>0.209722</td>\n",
       "      <td>0.096254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.912674</td>\n",
       "      <td>0.193104</td>\n",
       "      <td>-0.038881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.446930</td>\n",
       "      <td>0.156892</td>\n",
       "      <td>0.035872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.056656</td>\n",
       "      <td>0.212567</td>\n",
       "      <td>0.006812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.107605</td>\n",
       "      <td>0.189522</td>\n",
       "      <td>0.013451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>-14.182739</td>\n",
       "      <td>0.093291</td>\n",
       "      <td>-0.011626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>-22.805542</td>\n",
       "      <td>0.103310</td>\n",
       "      <td>-0.018983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>11.609253</td>\n",
       "      <td>0.147959</td>\n",
       "      <td>0.009709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>-2.362549</td>\n",
       "      <td>0.179949</td>\n",
       "      <td>-0.001968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>-2.461548</td>\n",
       "      <td>0.139988</td>\n",
       "      <td>-0.002055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      transformed  compound    logret\n",
       "1     14.228271    0.209722  0.096254\n",
       "2    -5.912674     0.193104 -0.038881\n",
       "3     5.446930     0.156892  0.035872\n",
       "4     1.056656     0.212567  0.006812\n",
       "5     2.107605     0.189522  0.013451\n",
       "...        ...          ...       ...\n",
       "1456 -14.182739    0.093291 -0.011626\n",
       "1457 -22.805542    0.103310 -0.018983\n",
       "1458  11.609253    0.147959  0.009709\n",
       "1459 -2.362549     0.179949 -0.001968\n",
       "1460 -2.461548     0.139988 -0.002055\n",
       "\n",
       "[1460 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedf[['transformed', 'compound', 'logret']].dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>VAR Order Selection (* highlights the minimums)</caption>\n",
       "<tr>\n",
       "   <td></td>      <th>AIC</th>         <th>BIC</th>         <th>FPE</th>        <th>HQIC</th>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>  <td>     8.629</td>  <td>     8.637</td>  <td>     5594.</td>  <td>     8.632</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>  <td>     2.953</td>  <td>     2.975</td>  <td>     19.17</td>  <td>     2.962</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>  <td>     2.891</td>  <td>     2.927</td>  <td>     18.00</td>  <td>     2.904</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>  <td>     2.863</td>  <td>     2.914*</td> <td>     17.51</td>  <td>     2.882</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>  <td>     2.849</td>  <td>     2.915</td>  <td>     17.27</td>  <td>     2.874</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>  <td>     2.843</td>  <td>     2.924</td>  <td>     17.17</td>  <td>     2.873</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>  <td>     2.837</td>  <td>     2.932</td>  <td>     17.06</td>  <td>     2.872</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>  <td>     2.830</td>  <td>     2.940</td>  <td>     16.95</td>  <td>     2.871*</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>  <td>     2.830</td>  <td>     2.955</td>  <td>     16.95</td>  <td>     2.877</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>  <td>     2.834</td>  <td>     2.973</td>  <td>     17.02</td>  <td>     2.886</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th> <td>     2.836</td>  <td>     2.990</td>  <td>     17.05</td>  <td>     2.893</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th> <td>     2.836</td>  <td>     3.004</td>  <td>     17.05</td>  <td>     2.899</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th> <td>     2.832</td>  <td>     3.015</td>  <td>     16.99</td>  <td>     2.901</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13</th> <td>     2.833</td>  <td>     3.031</td>  <td>     17.00</td>  <td>     2.907</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14</th> <td>     2.834</td>  <td>     3.047</td>  <td>     17.02</td>  <td>     2.914</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15</th> <td>     2.826</td>  <td>     3.053</td>  <td>     16.88</td>  <td>     2.911</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16</th> <td>     2.828</td>  <td>     3.070</td>  <td>     16.92</td>  <td>     2.918</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>17</th> <td>     2.826</td>  <td>     3.082</td>  <td>     16.88</td>  <td>     2.922</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>18</th> <td>     2.821*</td> <td>     3.091</td>  <td>     16.79*</td> <td>     2.922</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>19</th> <td>     2.823</td>  <td>     3.109</td>  <td>     16.84</td>  <td>     2.930</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>20</th> <td>     2.826</td>  <td>     3.126</td>  <td>     16.88</td>  <td>     2.938</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAR(mergedf[['Adj Close', 'compound']].dropna())\n",
    "\n",
    "x = model.select_order(maxlags=20)\n",
    "x.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Summary of Regression Results   \n",
       "==================================\n",
       "Model:                         VAR\n",
       "Method:                        OLS\n",
       "Date:           Wed, 07, Jun, 2023\n",
       "Time:                     14:02:20\n",
       "--------------------------------------------------------------------\n",
       "No. of Equations:         2.00000    BIC:                    3.08881\n",
       "Nobs:                     1443.00    HQIC:                   2.91928\n",
       "Log likelihood:          -6054.48    FPE:                    16.7491\n",
       "AIC:                      2.81832    Det(Omega_mle):         15.9221\n",
       "--------------------------------------------------------------------\n",
       "Results for equation Adj Close\n",
       "================================================================================\n",
       "                   coefficient       std. error           t-stat            prob\n",
       "--------------------------------------------------------------------------------\n",
       "const                -6.442358        10.769247           -0.598           0.550\n",
       "L1.Adj Close          0.945215         0.026658           35.457           0.000\n",
       "L1.compound         -17.210326        50.029787           -0.344           0.731\n",
       "L2.Adj Close          0.061123         0.036567            1.672           0.095\n",
       "L2.compound         -76.640443        52.016367           -1.473           0.141\n",
       "L3.Adj Close          0.022284         0.036560            0.610           0.542\n",
       "L3.compound          58.138302        52.352831            1.111           0.267\n",
       "L4.Adj Close          0.001660         0.036552            0.045           0.964\n",
       "L4.compound         -19.112013        52.449416           -0.364           0.716\n",
       "L5.Adj Close         -0.097876         0.036483           -2.683           0.007\n",
       "L5.compound          26.886326        52.449723            0.513           0.608\n",
       "L6.Adj Close          0.155961         0.036538            4.268           0.000\n",
       "L6.compound          31.683931        52.503265            0.603           0.546\n",
       "L7.Adj Close         -0.107088         0.036753           -2.914           0.004\n",
       "L7.compound         -34.872644        52.433385           -0.665           0.506\n",
       "L8.Adj Close         -0.013568         0.036782           -0.369           0.712\n",
       "L8.compound         -17.972536        53.015271           -0.339           0.735\n",
       "L9.Adj Close          0.043572         0.036768            1.185           0.236\n",
       "L9.compound          18.754711        53.087702            0.353           0.724\n",
       "L10.Adj Close         0.013719         0.036765            0.373           0.709\n",
       "L10.compound        -92.688161        53.079458           -1.746           0.081\n",
       "L11.Adj Close        -0.052292         0.036771           -1.422           0.155\n",
       "L11.compound        -75.756520        52.639340           -1.439           0.150\n",
       "L12.Adj Close        -0.017920         0.036734           -0.488           0.626\n",
       "L12.compound        140.099276        52.602651            2.663           0.008\n",
       "L13.Adj Close         0.067783         0.036507            1.857           0.063\n",
       "L13.compound         37.213377        52.689875            0.706           0.480\n",
       "L14.Adj Close        -0.075357         0.036445           -2.068           0.039\n",
       "L14.compound        -14.922918        52.620595           -0.284           0.777\n",
       "L15.Adj Close         0.060874         0.036556            1.665           0.096\n",
       "L15.compound         99.224955        52.479851            1.891           0.059\n",
       "L16.Adj Close        -0.078056         0.036592           -2.133           0.033\n",
       "L16.compound         -2.801809        52.406873           -0.053           0.957\n",
       "L17.Adj Close         0.121026         0.036589            3.308           0.001\n",
       "L17.compound         24.878630        52.226159            0.476           0.634\n",
       "L18.Adj Close        -0.054403         0.026653           -2.041           0.041\n",
       "L18.compound        -21.492015        49.743663           -0.432           0.666\n",
       "================================================================================\n",
       "\n",
       "Results for equation compound\n",
       "================================================================================\n",
       "                   coefficient       std. error           t-stat            prob\n",
       "--------------------------------------------------------------------------------\n",
       "const                 0.021918         0.005726            3.828           0.000\n",
       "L1.Adj Close          0.000000         0.000014            0.008           0.993\n",
       "L1.compound           0.283028         0.026601           10.640           0.000\n",
       "L2.Adj Close          0.000015         0.000019            0.753           0.451\n",
       "L2.compound           0.118612         0.027657            4.289           0.000\n",
       "L3.Adj Close         -0.000038         0.000019           -1.941           0.052\n",
       "L3.compound           0.091644         0.027836            3.292           0.001\n",
       "L4.Adj Close          0.000009         0.000019            0.486           0.627\n",
       "L4.compound           0.076768         0.027888            2.753           0.006\n",
       "L5.Adj Close         -0.000006         0.000019           -0.296           0.767\n",
       "L5.compound           0.041617         0.027888            1.492           0.136\n",
       "L6.Adj Close          0.000016         0.000019            0.808           0.419\n",
       "L6.compound           0.023598         0.027916            0.845           0.398\n",
       "L7.Adj Close          0.000017         0.000020            0.854           0.393\n",
       "L7.compound           0.022213         0.027879            0.797           0.426\n",
       "L8.Adj Close         -0.000006         0.000020           -0.328           0.743\n",
       "L8.compound           0.043036         0.028188            1.527           0.127\n",
       "L9.Adj Close          0.000016         0.000020            0.844           0.399\n",
       "L9.compound          -0.012478         0.028227           -0.442           0.658\n",
       "L10.Adj Close        -0.000008         0.000020           -0.416           0.678\n",
       "L10.compound         -0.001936         0.028223           -0.069           0.945\n",
       "L11.Adj Close        -0.000039         0.000020           -1.982           0.047\n",
       "L11.compound          0.044970         0.027989            1.607           0.108\n",
       "L12.Adj Close         0.000017         0.000020            0.865           0.387\n",
       "L12.compound         -0.029353         0.027969           -1.049           0.294\n",
       "L13.Adj Close        -0.000024         0.000019           -1.222           0.222\n",
       "L13.compound          0.011485         0.028015            0.410           0.682\n",
       "L14.Adj Close         0.000043         0.000019            2.205           0.027\n",
       "L14.compound         -0.012622         0.027979           -0.451           0.652\n",
       "L15.Adj Close        -0.000004         0.000019           -0.230           0.818\n",
       "L15.compound          0.058351         0.027904            2.091           0.037\n",
       "L16.Adj Close         0.000017         0.000019            0.876           0.381\n",
       "L16.compound          0.039715         0.027865            1.425           0.154\n",
       "L17.Adj Close         0.000017         0.000019            0.853           0.393\n",
       "L17.compound          0.032092         0.027769            1.156           0.248\n",
       "L18.Adj Close        -0.000040         0.000014           -2.827           0.005\n",
       "L18.compound          0.041158         0.026449            1.556           0.120\n",
       "================================================================================\n",
       "\n",
       "Correlation matrix of residuals\n",
       "             Adj Close  compound\n",
       "Adj Close     1.000000 -0.054350\n",
       "compound     -0.054350  1.000000\n",
       "\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fitted = model.fit(18)\n",
    "model_fitted.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portmentau and Durbin Watson tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Portmanteau-test for residual autocorrelation. H_0: residual autocorrelation up to lag 20 is zero. Conclusion: fail to reject H_0 at 5% significance level.</caption>\n",
       "<tr>\n",
       "  <th>Test statistic</th> <th>Critical value</th> <th>p-value</th> <th>df</th>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>13.62</td>          <td>15.51</td>      <td>0.092</td>   <td>8</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Portmentau = model_fitted.test_whiteness(nlags=20)\n",
    "Portmentau.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj Close : 1.9995378\n",
      "compound : 2.0000005\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "out = durbin_watson(model_fitted.resid)\n",
    "\n",
    "for col, val in zip(mergedf[['Adj Close', 'compound']].dropna().columns, out):\n",
    "    print(col, ':', round(val, 7))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Johansen test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "jres = coint_johansen(mergedf[['logret', 'compound']].dropna(), det_order=0, k_ar_diff=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum eigenvalue statistic : [67.25039578 13.15387281]\n",
      "Critical values (90%, 95%, 99%) of maximum eigenvalue statistic.: [[12.2971 14.2639 18.52  ]\n",
      " [ 2.7055  3.8415  6.6349]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Maximum eigenvalue statistic : {jres.max_eig_stat}' )\n",
    "print(f'Critical values (90%, 95%, 99%) of maximum eigenvalue statistic.: {jres.max_eig_stat_crit_vals}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues of VECM coefficient matrix : [0.04565889 0.00909933]\n",
      "Eigenvectors of VECM coefficient matrix : [[91.14037471  2.77375666]\n",
      " [-3.84283148 24.89111564]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Eigenvalues of VECM coefficient matrix : {jres.eig}' )\n",
    "print(f'Eigenvectors of VECM coefficient matrix : {jres.evec}' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granger Causality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.0816  , p=0.7752  , df_denom=1456, df_num=1\n",
      "ssr based chi2 test:   chi2=0.0817  , p=0.7750  , df=1\n",
      "likelihood ratio test: chi2=0.0817  , p=0.7750  , df=1\n",
      "parameter F test:         F=0.0816  , p=0.7752  , df_denom=1456, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.5572  , p=0.5729  , df_denom=1453, df_num=2\n",
      "ssr based chi2 test:   chi2=1.1183  , p=0.5717  , df=2\n",
      "likelihood ratio test: chi2=1.1179  , p=0.5718  , df=2\n",
      "parameter F test:         F=0.5572  , p=0.5729  , df_denom=1453, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.8558  , p=0.4635  , df_denom=1450, df_num=3\n",
      "ssr based chi2 test:   chi2=2.5799  , p=0.4610  , df=3\n",
      "likelihood ratio test: chi2=2.5776  , p=0.4614  , df=3\n",
      "parameter F test:         F=0.8558  , p=0.4635  , df_denom=1450, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.6842  , p=0.6029  , df_denom=1447, df_num=4\n",
      "ssr based chi2 test:   chi2=2.7538  , p=0.5998  , df=4\n",
      "likelihood ratio test: chi2=2.7512  , p=0.6003  , df=4\n",
      "parameter F test:         F=0.6842  , p=0.6029  , df_denom=1447, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.7323  , p=0.5992  , df_denom=1444, df_num=5\n",
      "ssr based chi2 test:   chi2=3.6896  , p=0.5949  , df=5\n",
      "likelihood ratio test: chi2=3.6849  , p=0.5956  , df=5\n",
      "parameter F test:         F=0.7323  , p=0.5992  , df_denom=1444, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=0.6499  , p=0.6903  , df_denom=1441, df_num=6\n",
      "ssr based chi2 test:   chi2=3.9346  , p=0.6855  , df=6\n",
      "likelihood ratio test: chi2=3.9293  , p=0.6862  , df=6\n",
      "parameter F test:         F=0.6499  , p=0.6903  , df_denom=1441, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=0.5907  , p=0.7640  , df_denom=1438, df_num=7\n",
      "ssr based chi2 test:   chi2=4.1778  , p=0.7591  , df=7\n",
      "likelihood ratio test: chi2=4.1719  , p=0.7598  , df=7\n",
      "parameter F test:         F=0.5907  , p=0.7640  , df_denom=1438, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=0.5097  , p=0.8498  , df_denom=1435, df_num=8\n",
      "ssr based chi2 test:   chi2=4.1262  , p=0.8456  , df=8\n",
      "likelihood ratio test: chi2=4.1204  , p=0.8461  , df=8\n",
      "parameter F test:         F=0.5097  , p=0.8498  , df_denom=1435, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=0.4909  , p=0.8815  , df_denom=1432, df_num=9\n",
      "ssr based chi2 test:   chi2=4.4766  , p=0.8773  , df=9\n",
      "likelihood ratio test: chi2=4.4697  , p=0.8779  , df=9\n",
      "parameter F test:         F=0.4909  , p=0.8815  , df_denom=1432, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=0.6555  , p=0.7664  , df_denom=1429, df_num=10\n",
      "ssr based chi2 test:   chi2=6.6516  , p=0.7579  , df=10\n",
      "likelihood ratio test: chi2=6.6363  , p=0.7593  , df=10\n",
      "parameter F test:         F=0.6555  , p=0.7664  , df_denom=1429, df_num=10\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 11\n",
      "ssr based F test:         F=0.5929  , p=0.8360  , df_denom=1426, df_num=11\n",
      "ssr based chi2 test:   chi2=6.6270  , p=0.8284  , df=11\n",
      "likelihood ratio test: chi2=6.6119  , p=0.8296  , df=11\n",
      "parameter F test:         F=0.5929  , p=0.8360  , df_denom=1426, df_num=11\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 12\n",
      "ssr based F test:         F=1.2893  , p=0.2182  , df_denom=1423, df_num=12\n",
      "ssr based chi2 test:   chi2=15.7430 , p=0.2033  , df=12\n",
      "likelihood ratio test: chi2=15.6580 , p=0.2074  , df=12\n",
      "parameter F test:         F=1.2893  , p=0.2182  , df_denom=1423, df_num=12\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 13\n",
      "ssr based F test:         F=1.2634  , p=0.2286  , df_denom=1420, df_num=13\n",
      "ssr based chi2 test:   chi2=16.7360 , p=0.2117  , df=13\n",
      "likelihood ratio test: chi2=16.6399 , p=0.2163  , df=13\n",
      "parameter F test:         F=1.2634  , p=0.2286  , df_denom=1420, df_num=13\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 14\n",
      "ssr based F test:         F=1.2106  , p=0.2606  , df_denom=1417, df_num=14\n",
      "ssr based chi2 test:   chi2=17.2946 , p=0.2408  , df=14\n",
      "likelihood ratio test: chi2=17.1920 , p=0.2461  , df=14\n",
      "parameter F test:         F=1.2106  , p=0.2606  , df_denom=1417, df_num=14\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 15\n",
      "ssr based F test:         F=1.3933  , p=0.1420  , df_denom=1414, df_num=15\n",
      "ssr based chi2 test:   chi2=21.3576 , p=0.1258  , df=15\n",
      "likelihood ratio test: chi2=21.2013 , p=0.1305  , df=15\n",
      "parameter F test:         F=1.3933  , p=0.1420  , df_denom=1414, df_num=15\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 16\n",
      "ssr based F test:         F=1.2807  , p=0.2008  , df_denom=1411, df_num=16\n",
      "ssr based chi2 test:   chi2=20.9709 , p=0.1796  , df=16\n",
      "likelihood ratio test: chi2=20.8200 , p=0.1855  , df=16\n",
      "parameter F test:         F=1.2807  , p=0.2008  , df_denom=1411, df_num=16\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 17\n",
      "ssr based F test:         F=1.2568  , p=0.2124  , df_denom=1408, df_num=17\n",
      "ssr based chi2 test:   chi2=21.8973 , p=0.1887  , df=17\n",
      "likelihood ratio test: chi2=21.7328 , p=0.1952  , df=17\n",
      "parameter F test:         F=1.2568  , p=0.2124  , df_denom=1408, df_num=17\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 18\n",
      "ssr based F test:         F=1.1944  , p=0.2570  , df_denom=1405, df_num=18\n",
      "ssr based chi2 test:   chi2=22.0648 , p=0.2291  , df=18\n",
      "likelihood ratio test: chi2=21.8977 , p=0.2366  , df=18\n",
      "parameter F test:         F=1.1944  , p=0.2570  , df_denom=1405, df_num=18\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 19\n",
      "ssr based F test:         F=1.1256  , p=0.3176  , df_denom=1402, df_num=19\n",
      "ssr based chi2 test:   chi2=21.9823 , p=0.2851  , df=19\n",
      "likelihood ratio test: chi2=21.8163 , p=0.2935  , df=19\n",
      "parameter F test:         F=1.1256  , p=0.3176  , df_denom=1402, df_num=19\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 20\n",
      "ssr based F test:         F=1.0699  , p=0.3755  , df_denom=1399, df_num=20\n",
      "ssr based chi2 test:   chi2=22.0250 , p=0.3392  , df=20\n",
      "likelihood ratio test: chi2=21.8583 , p=0.3483  , df=20\n",
      "parameter F test:         F=1.0699  , p=0.3755  , df_denom=1399, df_num=20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: ({'ssr_ftest': (0.08156653418149275, 0.7752262343107712, 1456.0, 1),\n",
       "   'ssr_chi2test': (0.08173459709532825, 0.7749603570599578, 1),\n",
       "   'lrtest': (0.0817323077499168, 0.7749634237739393, 1),\n",
       "   'params_ftest': (0.08156653418144462, 0.7752262343107712, 1456.0, 1.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b17ce20>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b17caf0>,\n",
       "   array([[0., 1., 0.]])]),\n",
       " 2: ({'ssr_ftest': (0.557243473915148, 0.5729081491025834, 1453.0, 2),\n",
       "   'ssr_chi2test': (1.118322071532396, 0.5716884889055245, 2),\n",
       "   'lrtest': (1.117893400369212, 0.5718110352228325, 2),\n",
       "   'params_ftest': (0.557243473915244, 0.5729081491024909, 1453.0, 2.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1d2a00>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1d2790>,\n",
       "   array([[0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1., 0.]])]),\n",
       " 3: ({'ssr_ftest': (0.8558260544537676, 0.4634651027249663, 1450.0, 3),\n",
       "   'ssr_chi2test': (2.579872885529254, 0.4610290208837913, 3),\n",
       "   'lrtest': (2.577591520479473, 0.4614315927216702, 3),\n",
       "   'params_ftest': (0.8558260544537847, 0.4634651027249663, 1450.0, 3.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1d25e0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1d2b50>,\n",
       "   array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 4: ({'ssr_ftest': (0.6841827942566377, 0.6029238387928957, 1447.0, 4),\n",
       "   'ssr_chi2test': (2.7537530019009386, 0.5998418332487223, 4),\n",
       "   'lrtest': (2.7511521750711836, 0.6002937763827183, 4),\n",
       "   'params_ftest': (0.6841827942565799, 0.6029238387929519, 1447.0, 4.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1cce50>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1cca00>,\n",
       "   array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 5: ({'ssr_ftest': (0.732339532582707, 0.5991993037505712, 1444.0, 5),\n",
       "   'ssr_chi2test': (3.6895914816753423, 0.5949136647849211, 5),\n",
       "   'lrtest': (3.684921338863205, 0.5956094839480297, 5),\n",
       "   'params_ftest': (0.7323395325826778, 0.5991993037505963, 1444.0, 5.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ccd90>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ccfa0>,\n",
       "   array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 6: ({'ssr_ftest': (0.6498982528055082, 0.690271452100768, 1441.0, 6),\n",
       "   'ssr_chi2test': (3.934567909420717, 0.6855308903891126, 6),\n",
       "   'lrtest': (3.929253963939118, 0.686249843848828, 6),\n",
       "   'params_ftest': (0.6498982528055182, 0.690271452100768, 1441.0, 6.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1cc880>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1cc730>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 7: ({'ssr_ftest': (0.5906742644347464, 0.7639911799630583, 1438.0, 7),\n",
       "   'ssr_chi2test': (4.177849752131993, 0.7590799193172967, 7),\n",
       "   'lrtest': (4.171854899272148, 0.759784032343953, 7),\n",
       "   'params_ftest': (0.5906742644347592, 0.7639911799630211, 1438.0, 7.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1cc8e0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b35f7c0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 8: ({'ssr_ftest': (0.509738450994164, 0.8497763549740401, 1435.0, 8),\n",
       "   'ssr_chi2test': (4.126217314807114, 0.8455598309037452, 8),\n",
       "   'lrtest': (4.120365564529493, 0.8461035633024487, 8),\n",
       "   'params_ftest': (0.5097384509942084, 0.8497763549740253, 1435.0, 8.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b35f850>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b35ff70>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0.]])]),\n",
       " 9: ({'ssr_ftest': (0.49089131007234577, 0.8815116510005871, 1432.0, 9),\n",
       "   'ssr_chi2test': (4.476640794856679, 0.8773413995472729, 9),\n",
       "   'lrtest': (4.46974927559495, 0.8778708875435401, 9),\n",
       "   'params_ftest': (0.49089131007231984, 0.8815116510005993, 1432.0, 9.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ec040>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ec2e0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0.]])]),\n",
       " 10: ({'ssr_ftest': (0.6555218315598218, 0.7663622258968031, 1429.0, 10),\n",
       "   'ssr_chi2test': (6.651551124994693, 0.7578800486129113, 10),\n",
       "   'lrtest': (6.636341368950525, 0.759272405400917, 10),\n",
       "   'params_ftest': (0.6555218315598063, 0.7663622258968188, 1429.0, 10.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ec6a0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ec5e0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0.]])]),\n",
       " 11: ({'ssr_ftest': (0.5928904356391876, 0.8359611499555075, 1426.0, 11),\n",
       "   'ssr_chi2test': (6.626985030612209, 0.8284368904533885, 11),\n",
       "   'lrtest': (6.611876857445168, 0.8295876688642472, 11),\n",
       "   'params_ftest': (0.592890435639188, 0.8359611499555075, 1426.0, 11.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ec700>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ec880>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 12: ({'ssr_ftest': (1.2892641708556238, 0.2181677487859736, 1423.0, 12),\n",
       "   'ssr_chi2test': (15.742975567665018, 0.20329388135441803, 12),\n",
       "   'lrtest': (15.658010301274771, 0.20740660544821396, 12),\n",
       "   'params_ftest': (1.2892641708556192, 0.21816774878597825, 1423.0, 12.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ec9a0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ecb20>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 13: ({'ssr_ftest': (1.2633595168465086, 0.22858019527105977, 1420.0, 13),\n",
       "   'ssr_chi2test': (16.735954839013854, 0.21165755599169217, 13),\n",
       "   'lrtest': (16.639910935948137, 0.21629237026018572, 13),\n",
       "   'params_ftest': (1.263359516846515, 0.22858019527105977, 1420.0, 13.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ecd00>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ecdc0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 14: ({'ssr_ftest': (1.2105547927283382, 0.2605515609374973, 1417.0, 14),\n",
       "   'ssr_chi2test': (17.29461624840683, 0.2408174578830392, 14),\n",
       "   'lrtest': (17.1920090475287, 0.2460900282362327, 14),\n",
       "   'params_ftest': (1.2105547927283293, 0.2605515609374973, 1417.0, 14.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1ecfa0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fb070>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 15: ({'ssr_ftest': (1.3932941508643673, 0.14196624445245948, 1414.0, 15),\n",
       "   'ssr_chi2test': (21.357603055152165, 0.1257875975832836, 15),\n",
       "   'lrtest': (21.201304863254336, 0.1305199269005392, 15),\n",
       "   'params_ftest': (1.3932941508643826, 0.14196624445246062, 1414.0, 15.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fb340>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fb1c0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 16: ({'ssr_ftest': (1.280725634465397, 0.20084579300989497, 1411.0, 16),\n",
       "   'ssr_chi2test': (20.97086113301809, 0.17963336682938805, 16),\n",
       "   'lrtest': (20.82004222330943, 0.1855321517952235, 16),\n",
       "   'params_ftest': (1.2807256344653923, 0.20084579300989497, 1411.0, 16.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fb490>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fb100>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0.]])]),\n",
       " 17: ({'ssr_ftest': (1.2568319941983366, 0.21237364624417565, 1408.0, 17),\n",
       "   'ssr_chi2test': (21.89726253528366, 0.18870242438790685, 17),\n",
       "   'lrtest': (21.732780945334525, 0.1952152294426519, 17),\n",
       "   'params_ftest': (1.256831994198322, 0.21237364624418528, 1408.0, 17.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fb7c0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fb4f0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0.]])]),\n",
       " 18: ({'ssr_ftest': (1.1943679807935557, 0.2569871049029174, 1405.0, 18),\n",
       "   'ssr_chi2test': (22.06477957969931, 0.2291218255428208, 18),\n",
       "   'lrtest': (21.897669871766993, 0.23655997620691202, 18),\n",
       "   'params_ftest': (1.1943679807935537, 0.2569871049029174, 1405.0, 18.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fbc10>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fbb80>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0.]])]),\n",
       " 19: ({'ssr_ftest': (1.125648319281631, 0.3175638797936443, 1402.0, 19),\n",
       "   'ssr_chi2test': (21.982257727255185, 0.2851401568799322, 19),\n",
       "   'lrtest': (21.81627545707306, 0.2934951706796419, 19),\n",
       "   'params_ftest': (1.125648319281643, 0.31756387979362627, 1402.0, 19.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fbcd0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fbdc0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 20: ({'ssr_ftest': (1.0698951552099258, 0.37552513977415947, 1399.0, 20),\n",
       "   'ssr_chi2test': (22.025003909968454, 0.33915540492671936, 20),\n",
       "   'lrtest': (21.85826418868237, 0.3482508958928049, 20),\n",
       "   'params_ftest': (1.0698951552099452, 0.3755251397741317, 1399.0, 20.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fbee0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1fbe50>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grangercausalitytests(mergedf[['transformed', 'compound']].dropna(), maxlag=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.1216  , p=0.7274  , df_denom=1456, df_num=1\n",
      "ssr based chi2 test:   chi2=0.1219  , p=0.7270  , df=1\n",
      "likelihood ratio test: chi2=0.1218  , p=0.7270  , df=1\n",
      "parameter F test:         F=0.1216  , p=0.7274  , df_denom=1456, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=1.0079  , p=0.3653  , df_denom=1453, df_num=2\n",
      "ssr based chi2 test:   chi2=2.0227  , p=0.3637  , df=2\n",
      "likelihood ratio test: chi2=2.0213  , p=0.3640  , df=2\n",
      "parameter F test:         F=1.0079  , p=0.3653  , df_denom=1453, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=1.0614  , p=0.3644  , df_denom=1450, df_num=3\n",
      "ssr based chi2 test:   chi2=3.1996  , p=0.3619  , df=3\n",
      "likelihood ratio test: chi2=3.1960  , p=0.3624  , df=3\n",
      "parameter F test:         F=1.0614  , p=0.3644  , df_denom=1450, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.9398  , p=0.4399  , df_denom=1447, df_num=4\n",
      "ssr based chi2 test:   chi2=3.7827  , p=0.4362  , df=4\n",
      "likelihood ratio test: chi2=3.7778  , p=0.4369  , df=4\n",
      "parameter F test:         F=0.9398  , p=0.4399  , df_denom=1447, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.0101  , p=0.4102  , df_denom=1444, df_num=5\n",
      "ssr based chi2 test:   chi2=5.0892  , p=0.4051  , df=5\n",
      "likelihood ratio test: chi2=5.0803  , p=0.4062  , df=5\n",
      "parameter F test:         F=1.0101  , p=0.4102  , df_denom=1444, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=0.8939  , p=0.4985  , df_denom=1441, df_num=6\n",
      "ssr based chi2 test:   chi2=5.4115  , p=0.4922  , df=6\n",
      "likelihood ratio test: chi2=5.4014  , p=0.4934  , df=6\n",
      "parameter F test:         F=0.8939  , p=0.4985  , df_denom=1441, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=0.8650  , p=0.5336  , df_denom=1438, df_num=7\n",
      "ssr based chi2 test:   chi2=6.1182  , p=0.5260  , df=7\n",
      "likelihood ratio test: chi2=6.1053  , p=0.5275  , df=7\n",
      "parameter F test:         F=0.8650  , p=0.5336  , df_denom=1438, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=0.8486  , p=0.5598  , df_denom=1435, df_num=8\n",
      "ssr based chi2 test:   chi2=6.8691  , p=0.5508  , df=8\n",
      "likelihood ratio test: chi2=6.8529  , p=0.5526  , df=8\n",
      "parameter F test:         F=0.8486  , p=0.5598  , df_denom=1435, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=0.9372  , p=0.4914  , df_denom=1432, df_num=9\n",
      "ssr based chi2 test:   chi2=8.5468  , p=0.4801  , df=9\n",
      "likelihood ratio test: chi2=8.5217  , p=0.4825  , df=9\n",
      "parameter F test:         F=0.9372  , p=0.4914  , df_denom=1432, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.0159  , p=0.4273  , df_denom=1429, df_num=10\n",
      "ssr based chi2 test:   chi2=10.3082 , p=0.4139  , df=10\n",
      "likelihood ratio test: chi2=10.2718 , p=0.4170  , df=10\n",
      "parameter F test:         F=1.0159  , p=0.4273  , df_denom=1429, df_num=10\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 11\n",
      "ssr based F test:         F=1.1062  , p=0.3521  , df_denom=1426, df_num=11\n",
      "ssr based chi2 test:   chi2=12.3646 , p=0.3369  , df=11\n",
      "likelihood ratio test: chi2=12.3121 , p=0.3406  , df=11\n",
      "parameter F test:         F=1.1062  , p=0.3521  , df_denom=1426, df_num=11\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 12\n",
      "ssr based F test:         F=1.0263  , p=0.4214  , df_denom=1423, df_num=12\n",
      "ssr based chi2 test:   chi2=12.5325 , p=0.4039  , df=12\n",
      "likelihood ratio test: chi2=12.4786 , p=0.4080  , df=12\n",
      "parameter F test:         F=1.0263  , p=0.4214  , df_denom=1423, df_num=12\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 13\n",
      "ssr based F test:         F=1.2220  , p=0.2569  , df_denom=1420, df_num=13\n",
      "ssr based chi2 test:   chi2=16.1875 , p=0.2392  , df=13\n",
      "likelihood ratio test: chi2=16.0977 , p=0.2439  , df=13\n",
      "parameter F test:         F=1.2220  , p=0.2569  , df_denom=1420, df_num=13\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 14\n",
      "ssr based F test:         F=1.2111  , p=0.2602  , df_denom=1417, df_num=14\n",
      "ssr based chi2 test:   chi2=17.3022 , p=0.2404  , df=14\n",
      "likelihood ratio test: chi2=17.1995 , p=0.2457  , df=14\n",
      "parameter F test:         F=1.2111  , p=0.2602  , df_denom=1417, df_num=14\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 15\n",
      "ssr based F test:         F=1.1452  , p=0.3098  , df_denom=1414, df_num=15\n",
      "ssr based chi2 test:   chi2=17.5553 , p=0.2868  , df=15\n",
      "likelihood ratio test: chi2=17.4495 , p=0.2927  , df=15\n",
      "parameter F test:         F=1.1452  , p=0.3098  , df_denom=1414, df_num=15\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 16\n",
      "ssr based F test:         F=1.2865  , p=0.1970  , df_denom=1411, df_num=16\n",
      "ssr based chi2 test:   chi2=21.0660 , p=0.1760  , df=16\n",
      "likelihood ratio test: chi2=20.9139 , p=0.1818  , df=16\n",
      "parameter F test:         F=1.2865  , p=0.1970  , df_denom=1411, df_num=16\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 17\n",
      "ssr based F test:         F=1.7269  , p=0.0326  , df_denom=1408, df_num=17\n",
      "ssr based chi2 test:   chi2=30.0876 , p=0.0257  , df=17\n",
      "likelihood ratio test: chi2=29.7782 , p=0.0280  , df=17\n",
      "parameter F test:         F=1.7269  , p=0.0326  , df_denom=1408, df_num=17\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 18\n",
      "ssr based F test:         F=1.6860  , p=0.0356  , df_denom=1405, df_num=18\n",
      "ssr based chi2 test:   chi2=31.1474 , p=0.0277  , df=18\n",
      "likelihood ratio test: chi2=30.8157 , p=0.0302  , df=18\n",
      "parameter F test:         F=1.6860  , p=0.0356  , df_denom=1405, df_num=18\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 19\n",
      "ssr based F test:         F=1.7207  , p=0.0273  , df_denom=1402, df_num=19\n",
      "ssr based chi2 test:   chi2=33.6020 , p=0.0205  , df=19\n",
      "likelihood ratio test: chi2=33.2163 , p=0.0227  , df=19\n",
      "parameter F test:         F=1.7207  , p=0.0273  , df_denom=1402, df_num=19\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 20\n",
      "ssr based F test:         F=1.6813  , p=0.0302  , df_denom=1399, df_num=20\n",
      "ssr based chi2 test:   chi2=34.6118 , p=0.0223  , df=20\n",
      "likelihood ratio test: chi2=34.2024 , p=0.0248  , df=20\n",
      "parameter F test:         F=1.6813  , p=0.0302  , df_denom=1399, df_num=20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: ({'ssr_ftest': (0.1216023537902205, 0.7273534814651768, 1456.0, 1),\n",
       "   'ssr_chi2test': (0.12185290809061243, 0.7270334858123686, 1),\n",
       "   'lrtest': (0.12184781991163618, 0.7270389572261404, 1),\n",
       "   'params_ftest': (0.12160235379139159, 0.7273534814639586, 1456.0, 1.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1d2220>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1d2820>,\n",
       "   array([[0., 1., 0.]])]),\n",
       " 2: ({'ssr_ftest': (1.0078608709639572, 0.3652539467177327, 1453.0, 2),\n",
       "   'ssr_chi2test': (2.022658155355058, 0.3637352258004222, 2),\n",
       "   'lrtest': (2.0212564522607863, 0.363990239549124, 2),\n",
       "   'params_ftest': (1.007860870964487, 0.36525394671753164, 1453.0, 2.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b208b20>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2084c0>,\n",
       "   array([[0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1., 0.]])]),\n",
       " 3: ({'ssr_ftest': (1.0613947615888046, 0.3644370871276813, 1450.0, 3),\n",
       "   'ssr_chi2test': (3.1995562088997684, 0.36186897529617795, 3),\n",
       "   'lrtest': (3.1960482482118096, 0.36237479607786804, 3),\n",
       "   'params_ftest': (1.0613947615880337, 0.36443708712799616, 1450.0, 3.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b208a60>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b208520>,\n",
       "   array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 4: ({'ssr_ftest': (0.9398229632152801, 0.43988850186383743, 1447.0, 4),\n",
       "   'ssr_chi2test': (3.7826737648692412, 0.43621593337743136, 4),\n",
       "   'lrtest': (3.7777685840446793, 0.4369161745398382, 4),\n",
       "   'params_ftest': (0.9398229632087978, 0.43988850186756245, 1447.0, 4.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b208b50>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b208a30>,\n",
       "   array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 5: ({'ssr_ftest': (1.0101488177897364, 0.41015124626052524, 1444.0, 5),\n",
       "   'ssr_chi2test': (5.0892192863021695, 0.40508914796040496, 5),\n",
       "   'lrtest': (5.08033959002023, 0.40615439234378087, 5),\n",
       "   'params_ftest': (1.0101488177863758, 0.41015124626254956, 1444.0, 5.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b208d60>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b208e20>,\n",
       "   array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 6: ({'ssr_ftest': (0.8938519214828481, 0.498464996822369, 1441.0, 6),\n",
       "   'ssr_chi2test': (5.411494908408305, 0.4922176217201789, 6),\n",
       "   'lrtest': (5.401449578543179, 0.4934469604107835, 6),\n",
       "   'params_ftest': (0.8938519214801296, 0.4984649968243481, 1441.0, 6.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1cc490>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1cc550>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 7: ({'ssr_ftest': (0.8649998979670308, 0.5335999148959882, 1438.0, 7),\n",
       "   'ssr_chi2test': (6.118159918096434, 0.526022277933377, 7),\n",
       "   'lrtest': (6.10531506778716, 0.5275075721028839, 7),\n",
       "   'params_ftest': (0.8649998979796168, 0.5335999148857951, 1438.0, 7.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1cc2e0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1cc250>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 8: ({'ssr_ftest': (0.8485847819321758, 0.5597987416200977, 1435.0, 8),\n",
       "   'ssr_chi2test': (6.869101621549934, 0.5508193725049896, 8),\n",
       "   'lrtest': (6.852904558969385, 0.5525832958047251, 8),\n",
       "   'params_ftest': (0.8485847819307125, 0.5597987416213621, 1435.0, 8.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b35fd60>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1cc100>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0.]])]),\n",
       " 9: ({'ssr_ftest': (0.937208485858088, 0.49139438126979673, 1432.0, 9),\n",
       "   'ssr_chi2test': (8.546791631858081, 0.48011482616745615, 9),\n",
       "   'lrtest': (8.52171855769302, 0.4825404174334772, 9),\n",
       "   'params_ftest': (0.9372084858487142, 0.4913943812780095, 1432.0, 9.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1918b0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b191730>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0.]])]),\n",
       " 10: ({'ssr_ftest': (1.015893319835224, 0.4273217478354271, 1429.0, 10),\n",
       "   'ssr_chi2test': (10.30822472890885, 0.4138805645211613, 10),\n",
       "   'lrtest': (10.271756260175607, 0.41698349857719946, 10),\n",
       "   'params_ftest': (1.0158933198343958, 0.42732174783609733, 1429.0, 10.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b191c40>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b191ca0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0.]])]),\n",
       " 11: ({'ssr_ftest': (1.106212149820181, 0.3521140057949384, 1426.0, 11),\n",
       "   'ssr_chi2test': (12.36459709395783, 0.3368707409327937, 11),\n",
       "   'lrtest': (12.312140548727257, 0.34064380778882347, 11),\n",
       "   'params_ftest': (1.1062121498183712, 0.3521140057963908, 1426.0, 11.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b191a60>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b191d00>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 12: ({'ssr_ftest': (1.0263468140448762, 0.4214129003496983, 1423.0, 12),\n",
       "   'ssr_chi2test': (12.532538468618249, 0.4039120995333446, 12),\n",
       "   'lrtest': (12.47861440318593, 0.40804626074876177, 12),\n",
       "   'params_ftest': (1.0263468140462306, 0.4214129003484075, 1423.0, 12.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b191bb0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b191f10>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 13: ({'ssr_ftest': (1.2219602118948347, 0.2568629804972264, 1420.0, 13),\n",
       "   'ssr_chi2test': (16.1875306661646, 0.2391514557976196, 13),\n",
       "   'lrtest': (16.097655703559212, 0.24389669935200323, 13),\n",
       "   'params_ftest': (1.2219602118957555, 0.25686298049659334, 1420.0, 13.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b14c2b0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b152dc0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 14: ({'ssr_ftest': (1.2110854094040062, 0.26015421421283014, 1417.0, 14),\n",
       "   'ssr_chi2test': (17.302196914590475, 0.2404311796363423, 14),\n",
       "   'lrtest': (17.19950009873719, 0.24570230924973827, 14),\n",
       "   'params_ftest': (1.2110854093873407, 0.26015421422530277, 1417.0, 14.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19f3a0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19f2e0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 15: ({'ssr_ftest': (1.1452462906828753, 0.3097704070429116, 1414.0, 15),\n",
       "   'ssr_chi2test': (17.55531354352993, 0.28676474597203583, 15),\n",
       "   'lrtest': (17.449529657045787, 0.2927089833990949, 15),\n",
       "   'params_ftest': (1.1452462906817809, 0.30977040704384856, 1414.0, 15.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19f700>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19f640>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 16: ({'ssr_ftest': (1.286538053811815, 0.19699941671036433, 1411.0, 16),\n",
       "   'ssr_chi2test': (21.066034865533783, 0.17598620451314728, 16),\n",
       "   'lrtest': (20.91385050947065, 0.18184590066116815, 16),\n",
       "   'params_ftest': (1.2865380538131297, 0.19699941670950094, 1411.0, 16.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19f8b0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19f790>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0.]])]),\n",
       " 17: ({'ssr_ftest': (1.7269316193992021, 0.03263556919735254, 1408.0, 17),\n",
       "   'ssr_chi2test': (30.087613320654707, 0.02572010547947794, 17),\n",
       "   'lrtest': (29.77823202775471, 0.027989474529478416, 17),\n",
       "   'params_ftest': (1.7269316193995916, 0.03263556919729439, 1408.0, 17.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19f940>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19fac0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0.]])]),\n",
       " 18: ({'ssr_ftest': (1.6860090135038104, 0.03558861664494809, 1405.0, 18),\n",
       "   'ssr_chi2test': (31.14736651566185, 0.027677482610508067, 18),\n",
       "   'lrtest': (30.815740106550948, 0.030231507033588692, 18),\n",
       "   'params_ftest': (1.6860090135030257, 0.03558861664507685, 1405.0, 18.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19fee0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19fe20>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0.]])]),\n",
       " 19: ({'ssr_ftest': (1.7206641577409776, 0.02734221568884754, 1402.0, 19),\n",
       "   'ssr_chi2test': (33.60204277802441, 0.020465490824905886, 19),\n",
       "   'lrtest': (33.216253040463926, 0.022695189667238914, 19),\n",
       "   'params_ftest': (1.7206641577408577, 0.027342215688863594, 1402.0, 19.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19ffa0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b19fd30>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 20: ({'ssr_ftest': (1.6813167708844416, 0.03015941249630439, 1399.0, 20),\n",
       "   'ssr_chi2test': (34.611810580037115, 0.022271927164388285, 20),\n",
       "   'lrtest': (34.20239370964009, 0.02478773614057519, 20),\n",
       "   'params_ftest': (1.681316770886379, 0.030159412496009654, 1399.0, 20.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1a0130>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1a02e0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grangercausalitytests(mergedf[['compound', 'transformed']].dropna(), maxlag=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=1.2999  , p=0.2544  , df_denom=1456, df_num=1\n",
      "ssr based chi2 test:   chi2=1.3026  , p=0.2537  , df=1\n",
      "likelihood ratio test: chi2=1.3020  , p=0.2538  , df=1\n",
      "parameter F test:         F=1.2999  , p=0.2544  , df_denom=1456, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.8772  , p=0.4162  , df_denom=1453, df_num=2\n",
      "ssr based chi2 test:   chi2=1.7604  , p=0.4147  , df=2\n",
      "likelihood ratio test: chi2=1.7594  , p=0.4149  , df=2\n",
      "parameter F test:         F=0.8772  , p=0.4162  , df_denom=1453, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.5102  , p=0.6753  , df_denom=1450, df_num=3\n",
      "ssr based chi2 test:   chi2=1.5379  , p=0.6735  , df=3\n",
      "likelihood ratio test: chi2=1.5371  , p=0.6737  , df=3\n",
      "parameter F test:         F=0.5102  , p=0.6753  , df_denom=1450, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.3531  , p=0.8420  , df_denom=1447, df_num=4\n",
      "ssr based chi2 test:   chi2=1.4211  , p=0.8405  , df=4\n",
      "likelihood ratio test: chi2=1.4204  , p=0.8406  , df=4\n",
      "parameter F test:         F=0.3531  , p=0.8420  , df_denom=1447, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.3112  , p=0.9064  , df_denom=1444, df_num=5\n",
      "ssr based chi2 test:   chi2=1.5679  , p=0.9051  , df=5\n",
      "likelihood ratio test: chi2=1.5670  , p=0.9052  , df=5\n",
      "parameter F test:         F=0.3112  , p=0.9064  , df_denom=1444, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=0.2577  , p=0.9563  , df_denom=1441, df_num=6\n",
      "ssr based chi2 test:   chi2=1.5603  , p=0.9554  , df=6\n",
      "likelihood ratio test: chi2=1.5595  , p=0.9554  , df=6\n",
      "parameter F test:         F=0.2577  , p=0.9563  , df_denom=1441, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=0.2167  , p=0.9817  , df_denom=1438, df_num=7\n",
      "ssr based chi2 test:   chi2=1.5327  , p=0.9812  , df=7\n",
      "likelihood ratio test: chi2=1.5319  , p=0.9812  , df=7\n",
      "parameter F test:         F=0.2167  , p=0.9817  , df_denom=1438, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=0.4433  , p=0.8953  , df_denom=1435, df_num=8\n",
      "ssr based chi2 test:   chi2=3.5884  , p=0.8922  , df=8\n",
      "likelihood ratio test: chi2=3.5840  , p=0.8926  , df=8\n",
      "parameter F test:         F=0.4433  , p=0.8953  , df_denom=1435, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=0.6029  , p=0.7954  , df_denom=1432, df_num=9\n",
      "ssr based chi2 test:   chi2=5.4980  , p=0.7889  , df=9\n",
      "likelihood ratio test: chi2=5.4876  , p=0.7899  , df=9\n",
      "parameter F test:         F=0.6029  , p=0.7954  , df_denom=1432, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=0.6575  , p=0.7646  , df_denom=1429, df_num=10\n",
      "ssr based chi2 test:   chi2=6.6712  , p=0.7561  , df=10\n",
      "likelihood ratio test: chi2=6.6559  , p=0.7575  , df=10\n",
      "parameter F test:         F=0.6575  , p=0.7646  , df_denom=1429, df_num=10\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 11\n",
      "ssr based F test:         F=0.7236  , p=0.7166  , df_denom=1426, df_num=11\n",
      "ssr based chi2 test:   chi2=8.0885  , p=0.7054  , df=11\n",
      "likelihood ratio test: chi2=8.0660  , p=0.7074  , df=11\n",
      "parameter F test:         F=0.7236  , p=0.7166  , df_denom=1426, df_num=11\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 12\n",
      "ssr based F test:         F=0.6724  , p=0.7793  , df_denom=1423, df_num=12\n",
      "ssr based chi2 test:   chi2=8.2107  , p=0.7685  , df=12\n",
      "likelihood ratio test: chi2=8.1875  , p=0.7703  , df=12\n",
      "parameter F test:         F=0.6724  , p=0.7793  , df_denom=1423, df_num=12\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 13\n",
      "ssr based F test:         F=0.6797  , p=0.7847  , df_denom=1420, df_num=13\n",
      "ssr based chi2 test:   chi2=9.0043  , p=0.7726  , df=13\n",
      "likelihood ratio test: chi2=8.9764  , p=0.7747  , df=13\n",
      "parameter F test:         F=0.6797  , p=0.7847  , df_denom=1420, df_num=13\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 14\n",
      "ssr based F test:         F=0.6280  , p=0.8435  , df_denom=1417, df_num=14\n",
      "ssr based chi2 test:   chi2=8.9723  , p=0.8328  , df=14\n",
      "likelihood ratio test: chi2=8.9446  , p=0.8346  , df=14\n",
      "parameter F test:         F=0.6280  , p=0.8435  , df_denom=1417, df_num=14\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 15\n",
      "ssr based F test:         F=0.5927  , p=0.8825  , df_denom=1414, df_num=15\n",
      "ssr based chi2 test:   chi2=9.0859  , p=0.8730  , df=15\n",
      "likelihood ratio test: chi2=9.0575  , p=0.8745  , df=15\n",
      "parameter F test:         F=0.5927  , p=0.8825  , df_denom=1414, df_num=15\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 16\n",
      "ssr based F test:         F=0.7264  , p=0.7689  , df_denom=1411, df_num=16\n",
      "ssr based chi2 test:   chi2=11.8948 , p=0.7512  , df=16\n",
      "likelihood ratio test: chi2=11.8460 , p=0.7545  , df=16\n",
      "parameter F test:         F=0.7264  , p=0.7689  , df_denom=1411, df_num=16\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 17\n",
      "ssr based F test:         F=1.0301  , p=0.4212  , df_denom=1408, df_num=17\n",
      "ssr based chi2 test:   chi2=17.9474 , p=0.3922  , df=17\n",
      "likelihood ratio test: chi2=17.8367 , p=0.3992  , df=17\n",
      "parameter F test:         F=1.0301  , p=0.4212  , df_denom=1408, df_num=17\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 18\n",
      "ssr based F test:         F=1.0350  , p=0.4161  , df_denom=1405, df_num=18\n",
      "ssr based chi2 test:   chi2=19.1199 , p=0.3845  , df=18\n",
      "likelihood ratio test: chi2=18.9943 , p=0.3922  , df=18\n",
      "parameter F test:         F=1.0350  , p=0.4161  , df_denom=1405, df_num=18\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 19\n",
      "ssr based F test:         F=1.0054  , p=0.4512  , df_denom=1402, df_num=19\n",
      "ssr based chi2 test:   chi2=19.6335 , p=0.4169  , df=19\n",
      "likelihood ratio test: chi2=19.5010 , p=0.4251  , df=19\n",
      "parameter F test:         F=1.0054  , p=0.4512  , df_denom=1402, df_num=19\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 20\n",
      "ssr based F test:         F=0.9526  , p=0.5189  , df_denom=1399, df_num=20\n",
      "ssr based chi2 test:   chi2=19.6110 , p=0.4825  , df=20\n",
      "likelihood ratio test: chi2=19.4786 , p=0.4909  , df=20\n",
      "parameter F test:         F=0.9526  , p=0.5189  , df_denom=1399, df_num=20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: ({'ssr_ftest': (1.299915564672148, 0.2544161620078955, 1456.0, 1),\n",
       "   'ssr_chi2test': (1.3025939621268297, 0.2537399496899383, 1),\n",
       "   'lrtest': (1.3020128305979597, 0.2538458840469284, 1),\n",
       "   'params_ftest': (1.2999155646724243, 0.2544161620078354, 1456.0, 1.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1d2400>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b17c7c0>,\n",
       "   array([[0., 1., 0.]])]),\n",
       " 2: ({'ssr_ftest': (0.8771999700857576, 0.41616610150260636, 1453.0, 2),\n",
       "   'ssr_chi2test': (1.7604371044529037, 0.41469226985808616, 2),\n",
       "   'lrtest': (1.7593751543899998, 0.41491251956749053, 2),\n",
       "   'params_ftest': (0.8771999700859318, 0.41616610150250544, 1453.0, 2.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1a0a00>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1a0a30>,\n",
       "   array([[0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1., 0.]])]),\n",
       " 3: ({'ssr_ftest': (0.5101779797487641, 0.6753055238724464, 1450.0, 3),\n",
       "   'ssr_chi2test': (1.5379227237805846, 0.6735458452895642, 3),\n",
       "   'lrtest': (1.5371116245223675, 0.6737318510710903, 3),\n",
       "   'params_ftest': (0.510177979748862, 0.6753055238723351, 1450.0, 3.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1a04f0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1a0a90>,\n",
       "   array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 4: ({'ssr_ftest': (0.3530797734270331, 0.8420011963360539, 1447.0, 4),\n",
       "   'ssr_chi2test': (1.4211033866199314, 0.8405189778398805, 4),\n",
       "   'lrtest': (1.4204103159772785, 0.8406399606970272, 4),\n",
       "   'params_ftest': (0.35307977342701685, 0.8420011963360818, 1447.0, 4.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1a0c10>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1a0e20>,\n",
       "   array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 5: ({'ssr_ftest': (0.31120693391182647, 0.9064221239142682, 1444.0, 5),\n",
       "   'ssr_chi2test': (1.56788811925799, 0.9051050850477601, 5),\n",
       "   'lrtest': (1.5670439582336257, 0.9052056948712108, 5),\n",
       "   'params_ftest': (0.311206933911844, 0.906422123914249, 1444.0, 5.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1a0eb0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b11f0>,\n",
       "   array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 6: ({'ssr_ftest': (0.2577324956785064, 0.9562626049654166, 1441.0, 6),\n",
       "   'ssr_chi2test': (1.5603457961827136, 0.9553856953634624, 6),\n",
       "   'lrtest': (1.5595091598115687, 0.9554440253161168, 6),\n",
       "   'params_ftest': (0.25773249567850876, 0.9562626049654166, 1441.0, 6.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b1430>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b10a0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 7: ({'ssr_ftest': (0.21670320876398774, 0.9816531741420139, 1438.0, 7),\n",
       "   'ssr_chi2test': (1.5327457137263696, 0.9811543017537561, 7),\n",
       "   'lrtest': (1.531937847737936, 0.981183328840576, 7),\n",
       "   'params_ftest': (0.21670320876398, 0.9816531741420139, 1438.0, 7.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b1640>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b1340>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 8: ({'ssr_ftest': (0.4433018198445441, 0.8953190277998091, 1435.0, 8),\n",
       "   'ssr_chi2test': (3.58842783227472, 0.892219462879472, 8),\n",
       "   'lrtest': (3.5840009596904565, 0.8925734585363594, 8),\n",
       "   'params_ftest': (0.443301819844547, 0.8953190277998091, 1435.0, 8.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b1820>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b18e0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0.]])]),\n",
       " 9: ({'ssr_ftest': (0.6028877735827202, 0.7954274335986053, 1432.0, 9),\n",
       "   'ssr_chi2test': (5.497982845821747, 0.7889191490883035, 9),\n",
       "   'lrtest': (5.487592882260287, 0.7899028560942317, 9),\n",
       "   'params_ftest': (0.6028877735827032, 0.7954274335986363, 1432.0, 9.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b1cd0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b1bb0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0.]])]),\n",
       " 10: ({'ssr_ftest': (0.6574572414881901, 0.7646077370386232, 1429.0, 10),\n",
       "   'ssr_chi2test': (6.671189644211866, 0.756079092677095, 10),\n",
       "   'lrtest': (6.655890080442987, 0.7574824497678403, 10),\n",
       "   'params_ftest': (0.6574572414882199, 0.7646077370386083, 1429.0, 10.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b1e50>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b1d30>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0.]])]),\n",
       " 11: ({'ssr_ftest': (0.7236470126272462, 0.7166142366289665, 1426.0, 11),\n",
       "   'ssr_chi2test': (8.088506125010994, 0.7053543146996688, 11),\n",
       "   'lrtest': (8.066014242265737, 0.7073784383051036, 11),\n",
       "   'params_ftest': (0.7236470126272437, 0.7166142366289665, 1426.0, 11.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1b1f70>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b228070>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 12: ({'ssr_ftest': (0.6724146373159274, 0.7792879858530262, 1423.0, 12),\n",
       "   'ssr_chi2test': (8.210735585384086, 0.7684528522109213, 12),\n",
       "   'lrtest': (8.187544146581786, 0.7703080351481953, 12),\n",
       "   'params_ftest': (0.6724146373159385, 0.7792879858530005, 1423.0, 12.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b228490>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2283d0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 13: ({'ssr_ftest': (0.679714232403271, 0.7846966422820967, 1420.0, 13),\n",
       "   'ssr_chi2test': (9.004298891364739, 0.772618784911862, 13),\n",
       "   'lrtest': (8.976398887329196, 0.7747236807088185, 13),\n",
       "   'params_ftest': (0.679714232403242, 0.7846966422821082, 1420.0, 13.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2287c0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b228700>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 14: ({'ssr_ftest': (0.6280244197566288, 0.8435067598560498, 1417.0, 14),\n",
       "   'ssr_chi2test': (8.972283947461674, 0.8328219597428069, 14),\n",
       "   'lrtest': (8.944562503045745, 0.8345854185531995, 14),\n",
       "   'params_ftest': (0.6280244197566248, 0.8435067598560602, 1417.0, 14.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2289d0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2288e0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 15: ({'ssr_ftest': (0.5927345144740516, 0.8824902440129507, 1414.0, 15),\n",
       "   'ssr_chi2test': (9.085941019253939, 0.8729811215749307, 15),\n",
       "   'lrtest': (9.057494691007378, 0.8744920762550943, 15),\n",
       "   'params_ftest': (0.5927345144740511, 0.8824902440129507, 1414.0, 15.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b228c70>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b228be0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 16: ({'ssr_ftest': (0.726432475675928, 0.7688580134342553, 1411.0, 16),\n",
       "   'ssr_chi2test': (11.894752599586562, 0.7511925045438157, 16),\n",
       "   'lrtest': (11.846029285239638, 0.7545091347146822, 16),\n",
       "   'params_ftest': (0.7264324756759344, 0.7688580134342466, 1411.0, 16.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b228df0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2284f0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0.]])]),\n",
       " 17: ({'ssr_ftest': (1.0301202151508704, 0.4212460861882961, 1408.0, 17),\n",
       "   'ssr_chi2test': (17.94735724280256, 0.39216924654616614, 17),\n",
       "   'lrtest': (17.836663727681298, 0.3992147537176163, 17),\n",
       "   'params_ftest': (1.030120215150884, 0.42124608618829157, 1408.0, 17.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b228310>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b229100>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0.]])]),\n",
       " 18: ({'ssr_ftest': (1.0349626100446778, 0.4160700625079446, 1405.0, 18),\n",
       "   'ssr_chi2test': (19.119921356811144, 0.3844739431204361, 18),\n",
       "   'lrtest': (18.99427235936855, 0.3921762712299651, 18),\n",
       "   'params_ftest': (1.0349626100446618, 0.4160700625079715, 1405.0, 18.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b229220>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b229370>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0.]])]),\n",
       " 19: ({'ssr_ftest': (1.0053765218721187, 0.4512072420744267, 1402.0, 19),\n",
       "   'ssr_chi2test': (19.63352624275088, 0.4169255951849334, 19),\n",
       "   'lrtest': (19.50097615143204, 0.42514812095427457, 19),\n",
       "   'params_ftest': (1.0053765218721302, 0.45120724207440305, 1402.0, 19.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2297c0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b229700>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 20: ({'ssr_ftest': (0.9526300829439458, 0.5188717374190603, 1399.0, 20),\n",
       "   'ssr_chi2test': (19.610969541662357, 0.48248960271113484, 20),\n",
       "   'lrtest': (19.4786314671328, 0.4909384317644224, 20),\n",
       "   'params_ftest': (0.9526300829439436, 0.518871737419077, 1399.0, 20.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b229a60>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2299a0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grangercausalitytests(mergedf[['compound', 'logret']].dropna(), maxlag=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.7094  , p=0.3998  , df_denom=1456, df_num=1\n",
      "ssr based chi2 test:   chi2=0.7108  , p=0.3992  , df=1\n",
      "likelihood ratio test: chi2=0.7107  , p=0.3992  , df=1\n",
      "parameter F test:         F=0.7094  , p=0.3998  , df_denom=1456, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.4999  , p=0.6067  , df_denom=1453, df_num=2\n",
      "ssr based chi2 test:   chi2=1.0032  , p=0.6056  , df=2\n",
      "likelihood ratio test: chi2=1.0029  , p=0.6057  , df=2\n",
      "parameter F test:         F=0.4999  , p=0.6067  , df_denom=1453, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.4433  , p=0.7221  , df_denom=1450, df_num=3\n",
      "ssr based chi2 test:   chi2=1.3363  , p=0.7205  , df=3\n",
      "likelihood ratio test: chi2=1.3356  , p=0.7207  , df=3\n",
      "parameter F test:         F=0.4433  , p=0.7221  , df_denom=1450, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.2929  , p=0.8827  , df_denom=1447, df_num=4\n",
      "ssr based chi2 test:   chi2=1.1790  , p=0.8815  , df=4\n",
      "likelihood ratio test: chi2=1.1785  , p=0.8816  , df=4\n",
      "parameter F test:         F=0.2929  , p=0.8827  , df_denom=1447, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.2440  , p=0.9429  , df_denom=1444, df_num=5\n",
      "ssr based chi2 test:   chi2=1.2293  , p=0.9420  , df=5\n",
      "likelihood ratio test: chi2=1.2288  , p=0.9421  , df=5\n",
      "parameter F test:         F=0.2440  , p=0.9429  , df_denom=1444, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=0.2364  , p=0.9646  , df_denom=1441, df_num=6\n",
      "ssr based chi2 test:   chi2=1.4313  , p=0.9639  , df=6\n",
      "likelihood ratio test: chi2=1.4306  , p=0.9640  , df=6\n",
      "parameter F test:         F=0.2364  , p=0.9646  , df_denom=1441, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=0.2043  , p=0.9846  , df_denom=1438, df_num=7\n",
      "ssr based chi2 test:   chi2=1.4450  , p=0.9842  , df=7\n",
      "likelihood ratio test: chi2=1.4443  , p=0.9842  , df=7\n",
      "parameter F test:         F=0.2043  , p=0.9846  , df_denom=1438, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=0.1993  , p=0.9910  , df_denom=1435, df_num=8\n",
      "ssr based chi2 test:   chi2=1.6134  , p=0.9907  , df=8\n",
      "likelihood ratio test: chi2=1.6125  , p=0.9907  , df=8\n",
      "parameter F test:         F=0.1993  , p=0.9910  , df_denom=1435, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=0.1229  , p=0.9991  , df_denom=1432, df_num=9\n",
      "ssr based chi2 test:   chi2=1.1206  , p=0.9991  , df=9\n",
      "likelihood ratio test: chi2=1.1202  , p=0.9991  , df=9\n",
      "parameter F test:         F=0.1229  , p=0.9991  , df_denom=1432, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=0.2274  , p=0.9937  , df_denom=1429, df_num=10\n",
      "ssr based chi2 test:   chi2=2.3074  , p=0.9934  , df=10\n",
      "likelihood ratio test: chi2=2.3056  , p=0.9934  , df=10\n",
      "parameter F test:         F=0.2274  , p=0.9937  , df_denom=1429, df_num=10\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 11\n",
      "ssr based F test:         F=0.2223  , p=0.9962  , df_denom=1426, df_num=11\n",
      "ssr based chi2 test:   chi2=2.4842  , p=0.9959  , df=11\n",
      "likelihood ratio test: chi2=2.4821  , p=0.9960  , df=11\n",
      "parameter F test:         F=0.2223  , p=0.9962  , df_denom=1426, df_num=11\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 12\n",
      "ssr based F test:         F=0.5046  , p=0.9128  , df_denom=1423, df_num=12\n",
      "ssr based chi2 test:   chi2=6.1620  , p=0.9077  , df=12\n",
      "likelihood ratio test: chi2=6.1490  , p=0.9084  , df=12\n",
      "parameter F test:         F=0.5046  , p=0.9128  , df_denom=1423, df_num=12\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 13\n",
      "ssr based F test:         F=0.5457  , p=0.8967  , df_denom=1420, df_num=13\n",
      "ssr based chi2 test:   chi2=7.2290  , p=0.8900  , df=13\n",
      "likelihood ratio test: chi2=7.2110  , p=0.8910  , df=13\n",
      "parameter F test:         F=0.5457  , p=0.8967  , df_denom=1420, df_num=13\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 14\n",
      "ssr based F test:         F=0.5890  , p=0.8756  , df_denom=1417, df_num=14\n",
      "ssr based chi2 test:   chi2=8.4141  , p=0.8667  , df=14\n",
      "likelihood ratio test: chi2=8.3897  , p=0.8681  , df=14\n",
      "parameter F test:         F=0.5890  , p=0.8756  , df_denom=1417, df_num=14\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 15\n",
      "ssr based F test:         F=0.6546  , p=0.8303  , df_denom=1414, df_num=15\n",
      "ssr based chi2 test:   chi2=10.0337 , p=0.8176  , df=15\n",
      "likelihood ratio test: chi2=9.9990  , p=0.8198  , df=15\n",
      "parameter F test:         F=0.6546  , p=0.8303  , df_denom=1414, df_num=15\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 16\n",
      "ssr based F test:         F=0.6263  , p=0.8648  , df_denom=1411, df_num=16\n",
      "ssr based chi2 test:   chi2=10.2558 , p=0.8529  , df=16\n",
      "likelihood ratio test: chi2=10.2196 , p=0.8549  , df=16\n",
      "parameter F test:         F=0.6263  , p=0.8648  , df_denom=1411, df_num=16\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 17\n",
      "ssr based F test:         F=0.6886  , p=0.8168  , df_denom=1408, df_num=17\n",
      "ssr based chi2 test:   chi2=11.9976 , p=0.8003  , df=17\n",
      "likelihood ratio test: chi2=11.9480 , p=0.8033  , df=17\n",
      "parameter F test:         F=0.6886  , p=0.8168  , df_denom=1408, df_num=17\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 18\n",
      "ssr based F test:         F=0.6397  , p=0.8704  , df_denom=1405, df_num=18\n",
      "ssr based chi2 test:   chi2=11.8185 , p=0.8565  , df=18\n",
      "likelihood ratio test: chi2=11.7703 , p=0.8589  , df=18\n",
      "parameter F test:         F=0.6397  , p=0.8704  , df_denom=1405, df_num=18\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 19\n",
      "ssr based F test:         F=0.6268  , p=0.8886  , df_denom=1402, df_num=19\n",
      "ssr based chi2 test:   chi2=12.2406 , p=0.8751  , df=19\n",
      "likelihood ratio test: chi2=12.1889 , p=0.8774  , df=19\n",
      "parameter F test:         F=0.6268  , p=0.8886  , df_denom=1402, df_num=19\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 20\n",
      "ssr based F test:         F=0.5951  , p=0.9185  , df_denom=1399, df_num=20\n",
      "ssr based chi2 test:   chi2=12.2515 , p=0.9071  , df=20\n",
      "likelihood ratio test: chi2=12.1997 , p=0.9090  , df=20\n",
      "parameter F test:         F=0.5951  , p=0.9185  , df_denom=1399, df_num=20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: ({'ssr_ftest': (0.7093719954288913, 0.3997906942249705, 1456.0, 1),\n",
       "   'ssr_chi2test': (0.710833613551341, 0.3991672112433441, 1),\n",
       "   'lrtest': (0.7106605085609772, 0.39922462624156074, 1),\n",
       "   'params_ftest': (0.7093719954291134, 0.3997906942248628, 1456.0, 1.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b17c7f0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b1d2b80>,\n",
       "   array([[0., 1., 0.]])]),\n",
       " 2: ({'ssr_ftest': (0.4998795609373919, 0.6067079958626346, 1453.0, 2),\n",
       "   'ssr_chi2test': (1.0031994492040157, 0.6055611533727476, 2),\n",
       "   'lrtest': (1.0028544739907375, 0.6056656141756046, 2),\n",
       "   'params_ftest': (0.4998795609374038, 0.6067079958626346, 1453.0, 2.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b229ca0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2298e0>,\n",
       "   array([[0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 1., 0.]])]),\n",
       " 3: ({'ssr_ftest': (0.4432802114650028, 0.7220954031583717, 1450.0, 3),\n",
       "   'ssr_chi2test': (1.3362605546989845, 0.7205411839925373, 3),\n",
       "   'lrtest': (1.3356481657938275, 0.720685972598057, 3),\n",
       "   'params_ftest': (0.4432802114650512, 0.7220954031582958, 1450.0, 3.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23e250>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23e160>,\n",
       "   array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 4: ({'ssr_ftest': (0.2929300005602461, 0.8826778079123672, 1447.0, 4),\n",
       "   'ssr_chi2test': (1.1790078253371619, 0.8815426016441859, 4),\n",
       "   'lrtest': (1.1785307272948558, 0.8816205864423418, 4),\n",
       "   'params_ftest': (0.2929300005603037, 0.8826778079123409, 1447.0, 4.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23e040>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23e0d0>,\n",
       "   array([[0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 5: ({'ssr_ftest': (0.24400758057186456, 0.9428674608561227, 1444.0, 5),\n",
       "   'ssr_chi2test': (1.2293318204018802, 0.942032613585941, 5),\n",
       "   'lrtest': (1.2288127805313707, 0.9420834840871182, 5),\n",
       "   'params_ftest': (0.24400758057187844, 0.9428674608561227, 1444.0, 5.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23e7c0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23e730>,\n",
       "   array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 6: ({'ssr_ftest': (0.23642535756789934, 0.9646415762319445, 1441.0, 6),\n",
       "   'ssr_chi2test': (1.4313496317989964, 0.9639236578215149, 6),\n",
       "   'lrtest': (1.4306455677706253, 0.9639677166354763, 6),\n",
       "   'params_ftest': (0.2364253575678564, 0.9646415762319546, 1441.0, 6.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23e490>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23e8e0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 7: ({'ssr_ftest': (0.20430411676242996, 0.9845740465793649, 1438.0, 7),\n",
       "   'ssr_chi2test': (1.4450467118154902, 0.9841514026034912, 7),\n",
       "   'lrtest': (1.4443286194054963, 0.9841746687317423, 7),\n",
       "   'params_ftest': (0.20430411676246132, 0.9845740465793547, 1438.0, 7.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23ed60>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23ecd0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 8: ({'ssr_ftest': (0.19930854348346924, 0.990979208831853, 1435.0, 8),\n",
       "   'ssr_chi2test': (1.6133575199330863, 0.9906617031246231, 8),\n",
       "   'lrtest': (1.6124618601643306, 0.9906791799725876, 8),\n",
       "   'params_ftest': (0.19930854348350877, 0.9909792088318469, 1435.0, 8.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23ec10>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b23ee80>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0.]])]),\n",
       " 9: ({'ssr_ftest': (0.122882834020786, 0.9991449236771647, 1432.0, 9),\n",
       "   'ssr_chi2test': (1.1206193641602264, 0.9991054915020349, 9),\n",
       "   'lrtest': (1.1201868550069776, 0.999106888622032, 9),\n",
       "   'params_ftest': (0.12288283402080408, 0.9991449236771637, 1432.0, 9.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b249100>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2490d0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0.]])]),\n",
       " 10: ({'ssr_ftest': (0.22739840345554746, 0.9937253417721157, 1429.0, 10),\n",
       "   'ssr_chi2test': (2.3074015746014265, 0.9933951415512091, 10),\n",
       "   'lrtest': (2.3055676226849755, 0.9934164711281172, 10),\n",
       "   'params_ftest': (0.22739840345553283, 0.9937253417721192, 1429.0, 10.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b249340>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2493d0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0.]])]),\n",
       " 11: ({'ssr_ftest': (0.22225581956490165, 0.9961827406815748, 1426.0, 11),\n",
       "   'ssr_chi2test': (2.484246499330271, 0.995940649023715, 11),\n",
       "   'lrtest': (2.48211936478765, 0.9959561942193331, 11),\n",
       "   'params_ftest': (0.22225581956492232, 0.9961827406815735, 1426.0, 11.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b2497c0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b249730>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 12: ({'ssr_ftest': (0.5046373664675161, 0.912821118920549, 1423.0, 12),\n",
       "   'ssr_chi2test': (6.162037160744595, 0.9076943414737666, 12),\n",
       "   'lrtest': (6.148962809756995, 0.9083873293673923, 12),\n",
       "   'params_ftest': (0.5046373664675244, 0.912821118920549, 1423.0, 12.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b249a30>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b249970>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 13: ({'ssr_ftest': (0.5457028215633278, 0.8967207518200108, 1420.0, 13),\n",
       "   'ssr_chi2test': (7.229025194667438, 0.8899662104070774, 13),\n",
       "   'lrtest': (7.211027474328148, 0.8909512583204215, 13),\n",
       "   'params_ftest': (0.5457028215633161, 0.8967207518200182, 1420.0, 13.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b249af0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b249bb0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 14: ({'ssr_ftest': (0.5889528028317155, 0.8755556708347744, 1417.0, 14),\n",
       "   'ssr_chi2test': (8.414086478846329, 0.8666575908177, 14),\n",
       "   'lrtest': (8.389700792185977, 0.8680520543319612, 14),\n",
       "   'params_ftest': (0.5889528028317285, 0.8755556708347573, 1417.0, 14.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b249f40>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b249e80>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 15: ({'ssr_ftest': (0.6545625035820336, 0.8303308034520156, 1414.0, 15),\n",
       "   'ssr_chi2test': (10.033693256817948, 0.8176151815011672, 15),\n",
       "   'lrtest': (9.999018040958617, 0.8198016829035469, 15),\n",
       "   'params_ftest': (0.6545625035820263, 0.8303308034520255, 1414.0, 15.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26a340>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26a2b0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 16: ({'ssr_ftest': (0.626341399790184, 0.8647677961829379, 1411.0, 16),\n",
       "   'ssr_chi2test': (10.25584103526039, 0.8529304208491679, 16),\n",
       "   'lrtest': (10.219592114419356, 0.8549117361905634, 16),\n",
       "   'params_ftest': (0.626341399790198, 0.8647677961829223, 1411.0, 16.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26a4c0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26a430>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0.]])]),\n",
       " 17: ({'ssr_ftest': (0.6886233624387823, 0.8167768366591361, 1408.0, 17),\n",
       "   'ssr_chi2test': (11.997599221580804, 0.8002825734459212, 17),\n",
       "   'lrtest': (11.947997880026378, 0.8032758728482032, 17),\n",
       "   'params_ftest': (0.688623362438779, 0.8167768366591361, 1408.0, 17.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26a7c0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26a550>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0.]])]),\n",
       " 18: ({'ssr_ftest': (0.6397363553078455, 0.870363240285575, 1405.0, 18),\n",
       "   'ssr_chi2test': (11.818503087808137, 0.8564648515472112, 18),\n",
       "   'lrtest': (11.77033440228115, 0.8588651214725791, 18),\n",
       "   'params_ftest': (0.6397363553078349, 0.8703632402855831, 1405.0, 18.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26a730>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26a910>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0.]])]),\n",
       " 19: ({'ssr_ftest': (0.6268048749663552, 0.8885638034025976, 1402.0, 19),\n",
       "   'ssr_chi2test': (12.240578225181057, 0.8750859977818493, 19),\n",
       "   'lrtest': (12.188881963211315, 0.8773936920916868, 19),\n",
       "   'params_ftest': (0.6268048749663396, 0.8885638034026044, 1402.0, 19.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26ad00>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26ac70>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0.]])]),\n",
       " 20: ({'ssr_ftest': (0.5951327014517621, 0.9185183310585976, 1399.0, 20),\n",
       "   'ssr_chi2test': (12.25148091623356, 0.9071482237836662, 20),\n",
       "   'lrtest': (12.199657019416918, 0.9090324802305446, 20),\n",
       "   'params_ftest': (0.5951327014517709, 0.918518331058592, 1399.0, 20.0)},\n",
       "  [<statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26adc0>,\n",
       "   <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x1349b26aeb0>,\n",
       "   array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 1., 0.]])])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grangercausalitytests(mergedf[['logret', 'compound']].dropna(), maxlag=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformed_x</th>\n",
       "      <th>compound_x</th>\n",
       "      <th>logret_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>transformed_y</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.6048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_y</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logret_y</th>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               transformed_x  compound_x  logret_x\n",
       "transformed_y  1.0000         0.1258      0.6048  \n",
       "compound_y     0.0257         1.0000      0.2537  \n",
       "logret_y       0.0561         0.3992      1.0000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize Granger Causality\n",
    "\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "maxlag=18\n",
    "test = 'ssr_chi2test'\n",
    "\n",
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n",
    "   \n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df\n",
    "\n",
    "grangers_causation_matrix(mergedf[['transformed', 'compound', 'logret']].dropna(), variables = mergedf[['transformed', 'compound', 'logret']].dropna().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>logret</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008347</td>\n",
       "      <td>0.255407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logret</th>\n",
       "      <td>0.008347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adj Close</th>\n",
       "      <td>0.255407</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           compound    logret  Adj Close\n",
       "compound   1.000000  0.008347  0.255407 \n",
       "logret     0.008347  1.000000  0.005947 \n",
       "Adj Close  0.255407  0.005947  1.000000 "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check correlation\n",
    "\n",
    "mergedf[['compound', 'logret', 'Adj Close']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>transformed</th>\n",
       "      <th>logret</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>public_metrics.reply_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "      <th>public_metrics.impression_count</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1.461000e+03</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "      <td>1461.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1312.588731</td>\n",
       "      <td>1353.903535</td>\n",
       "      <td>1265.872924</td>\n",
       "      <td>1313.076391</td>\n",
       "      <td>1313.076391</td>\n",
       "      <td>1.594850e+10</td>\n",
       "      <td>0.723255</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>1.084650</td>\n",
       "      <td>0.668085</td>\n",
       "      <td>4.402768</td>\n",
       "      <td>0.216251</td>\n",
       "      <td>2.639658</td>\n",
       "      <td>0.032439</td>\n",
       "      <td>0.870462</td>\n",
       "      <td>0.097097</td>\n",
       "      <td>0.183608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1281.822150</td>\n",
       "      <td>1320.929916</td>\n",
       "      <td>1236.268561</td>\n",
       "      <td>1280.902420</td>\n",
       "      <td>1280.902420</td>\n",
       "      <td>1.036689e+10</td>\n",
       "      <td>87.472040</td>\n",
       "      <td>0.049269</td>\n",
       "      <td>0.687269</td>\n",
       "      <td>0.751350</td>\n",
       "      <td>2.384313</td>\n",
       "      <td>0.228890</td>\n",
       "      <td>33.465183</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>0.024720</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>0.061374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>104.645050</td>\n",
       "      <td>106.058876</td>\n",
       "      <td>95.184303</td>\n",
       "      <td>104.535301</td>\n",
       "      <td>104.535301</td>\n",
       "      <td>2.212109e+09</td>\n",
       "      <td>-919.390869</td>\n",
       "      <td>-0.550732</td>\n",
       "      <td>0.129555</td>\n",
       "      <td>0.081981</td>\n",
       "      <td>0.648164</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.669325</td>\n",
       "      <td>0.020434</td>\n",
       "      <td>-0.152912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>202.955399</td>\n",
       "      <td>210.595078</td>\n",
       "      <td>198.064499</td>\n",
       "      <td>204.055786</td>\n",
       "      <td>204.055786</td>\n",
       "      <td>8.429099e+09</td>\n",
       "      <td>-12.469933</td>\n",
       "      <td>-0.020302</td>\n",
       "      <td>0.701567</td>\n",
       "      <td>0.361741</td>\n",
       "      <td>2.878582</td>\n",
       "      <td>0.099432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.857458</td>\n",
       "      <td>0.082882</td>\n",
       "      <td>0.148091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>731.472839</td>\n",
       "      <td>754.299438</td>\n",
       "      <td>719.792236</td>\n",
       "      <td>737.803406</td>\n",
       "      <td>737.803406</td>\n",
       "      <td>1.395173e+10</td>\n",
       "      <td>0.424896</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.939547</td>\n",
       "      <td>0.540746</td>\n",
       "      <td>3.852385</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>0.872447</td>\n",
       "      <td>0.094109</td>\n",
       "      <td>0.177640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2161.939453</td>\n",
       "      <td>2274.397461</td>\n",
       "      <td>2081.923584</td>\n",
       "      <td>2160.768311</td>\n",
       "      <td>2160.768311</td>\n",
       "      <td>2.023571e+10</td>\n",
       "      <td>16.346497</td>\n",
       "      <td>0.026503</td>\n",
       "      <td>1.255714</td>\n",
       "      <td>0.767790</td>\n",
       "      <td>5.318111</td>\n",
       "      <td>0.260703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036547</td>\n",
       "      <td>0.885868</td>\n",
       "      <td>0.107856</td>\n",
       "      <td>0.217357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4810.071289</td>\n",
       "      <td>4891.704590</td>\n",
       "      <td>4718.039062</td>\n",
       "      <td>4812.087402</td>\n",
       "      <td>4812.087402</td>\n",
       "      <td>8.448291e+10</td>\n",
       "      <td>534.011230</td>\n",
       "      <td>0.230695</td>\n",
       "      <td>7.697037</td>\n",
       "      <td>18.011236</td>\n",
       "      <td>25.106618</td>\n",
       "      <td>3.605528</td>\n",
       "      <td>951.682784</td>\n",
       "      <td>0.150145</td>\n",
       "      <td>0.973875</td>\n",
       "      <td>0.312419</td>\n",
       "      <td>0.484791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close    Adj Close  \\\n",
       "count  1461.000000  1461.000000  1461.000000  1461.000000  1461.000000   \n",
       "mean   1312.588731  1353.903535  1265.872924  1313.076391  1313.076391   \n",
       "std    1281.822150  1320.929916  1236.268561  1280.902420  1280.902420   \n",
       "min    104.645050   106.058876   95.184303    104.535301   104.535301    \n",
       "25%    202.955399   210.595078   198.064499   204.055786   204.055786    \n",
       "50%    731.472839   754.299438   719.792236   737.803406   737.803406    \n",
       "75%    2161.939453  2274.397461  2081.923584  2160.768311  2160.768311   \n",
       "max    4810.071289  4891.704590  4718.039062  4812.087402  4812.087402   \n",
       "\n",
       "             Volume  transformed       logret  public_metrics.retweet_count  \\\n",
       "count  1.461000e+03  1460.000000  1460.000000  1461.000000                    \n",
       "mean   1.594850e+10  0.723255     0.001466     1.084650                       \n",
       "std    1.036689e+10  87.472040    0.049269     0.687269                       \n",
       "min    2.212109e+09 -919.390869  -0.550732     0.129555                       \n",
       "25%    8.429099e+09 -12.469933   -0.020302     0.701567                       \n",
       "50%    1.395173e+10  0.424896     0.001351     0.939547                       \n",
       "75%    2.023571e+10  16.346497    0.026503     1.255714                       \n",
       "max    8.448291e+10  534.011230   0.230695     7.697037                       \n",
       "\n",
       "       public_metrics.reply_count  public_metrics.like_count  \\\n",
       "count  1461.000000                 1461.000000                 \n",
       "mean   0.668085                    4.402768                    \n",
       "std    0.751350                    2.384313                    \n",
       "min    0.081981                    0.648164                    \n",
       "25%    0.361741                    2.878582                    \n",
       "50%    0.540746                    3.852385                    \n",
       "75%    0.767790                    5.318111                    \n",
       "max    18.011236                   25.106618                   \n",
       "\n",
       "       public_metrics.quote_count  public_metrics.impression_count  \\\n",
       "count  1461.000000                 1461.000000                       \n",
       "mean   0.216251                    2.639658                          \n",
       "std    0.228890                    33.465183                         \n",
       "min    0.013664                    0.000000                          \n",
       "25%    0.099432                    0.000000                          \n",
       "50%    0.147541                    0.000000                          \n",
       "75%    0.260703                    0.000000                          \n",
       "max    3.605528                    951.682784                        \n",
       "\n",
       "               neg          neu          pos     compound  \n",
       "count  1461.000000  1461.000000  1461.000000  1461.000000  \n",
       "mean   0.032439     0.870462     0.097097     0.183608     \n",
       "std    0.011649     0.024720     0.022663     0.061374     \n",
       "min    0.004284     0.669325     0.020434    -0.152912     \n",
       "25%    0.025791     0.857458     0.082882     0.148091     \n",
       "50%    0.030220     0.872447     0.094109     0.177640     \n",
       "75%    0.036547     0.885868     0.107856     0.217357     \n",
       "max    0.150145     0.973875     0.312419     0.484791     "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create descriptive statistics\n",
    "\n",
    "mergedf.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLFenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
